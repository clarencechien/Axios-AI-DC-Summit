[Music]
[Music]
[Music]
[Music]
[Music]
[Music]
[Music]
Hi.
[Music]
[Music]
Take a seat. Axios's AI Plus Summit in
DC is about to begin.
[Music]
Heat. Heat.
[Music]
[Music]
[Music]
[Music]
[Music]
Doom.
Yeah.
Please grab a seat. The show will begin
in just a moment.
[Music]
[Music]
Happy.
[Music]
Everybody
Hi everyone, I'm Ena Freed, chief
technology correspondent at Axios and
author of our daily AI Plus newsletter.
Thanks so much for coming to Axios's AI
Plus DC Summit. And if you aren't
already getting the newsletter, you
should go to axios.com or scan this QR
code and then we'll be in your inbox
every day with the latest scoops and
analysis on this fastchanging AI world.
I'll see you out there shortly.
[Music]
Heat.
Heat.
Heat. Heat. N.
[Music]
Heat.
Heat.
[Music]
Welcome aboard.
[Music]
Heat. Heat.
[Applause]
[Music]
Please give it up for Axio's chief
technology correspondent, Ena Freed.
Good afternoon everyone. Welcome to the
Axios AIDC Summit. I'm super glad you're
all here. Welcome. Whether you're here
with us in the room or tuning in on the
live stream, thank you. We're glad to
have you here. Please use the hashtag
Axiosai Summit if you want to talk about
it on social. And we're gathering in DC
for a reason. This is the place where a
lot of the policy debates, a lot of the
legislation is going to happen. So, how
AI is governed, who it serves, these are
the questions that are going to be
answered in part by the folks in this
room and in this city. Plus, it's
September. The weather's beautiful.
Congress is in session. Well, Congress
is in session. And AI isn't just about
the tech anymore. It's a business story.
Politics, geopolitics, environment,
civil rights, and we need to have these
conversations. The technology is
improving at an unbelievably rapid pace.
And while we've gravitated to a
political discussion faster than in any
technology I've ever covered, the
technology is moving faster. So, we need
to decide that policy now. And so, we're
excited to have a series of
conversations to really help us all
answer the question, what is it we want
out of this technology? Today, you'll
hear from CEOs, policy makers, and
innovators on the front lines. And
throughout the program, we'll bring you
some demos that bring this technology to
life. Okay, couple more things before we
get started. First, as you heard from
that very intelligent woman before, you
should sign up for the newsletter. I I
assume you all are cuz you're here, but
if not, you can go to
axios.com/newsletters.
You can get mine, you can get Mike
Allens, you can get all of them. And
it's time to crack out your 2026
calendars. I know there's at least one
person in the room who actually has one.
Thank you. Um, we're going to move our
AI Summit DC earlier next year. So,
we're going to be back here in DC with
the AI Plus Summit in March. So, make
plans for that. Um, we have a jam-packed
program today. Really excited for the
conversations. There will be one short
break later, but if you do need a few
minutes to have a conversation, take a
call, do some work. We have a co-working
space on the third floor. And I know
sometimes at these events, people get
confused. Not the back of the room, but
upstairs on the third floor. Anyway,
your badges have a QR code on them that
get you the Wi-Fi, everything you need.
And of course, for the folks in the
room, we're going to have a reception
when this is all over. So, without
further ado, let's start the program. Up
next, we're going to hear from two
people who are on the forefront of this
transformation. And to get that
conversation started, I'd like to
welcome our CEO and co-founder for
Axios, Jim Vanderhigh.
[Applause]
Thank you, Ena. Uh, thank you all for
being here. Uh, anybody who reads Axios
or knows me uh knows I'm uh AI obsessed.
Uh, we write about it constantly. We
experiment with it aggressively. I use
it daily. Uh, despite being a DC
publication with a I think a great
reputation covering politics. I spend
more time talking to the anthropics,
open AIS, Googles of the world uh than I
do uh talking to folks in the White
House and Congress these days. That's
how important I think the topic is. In
talking uh in thinking about that topic,
I've gotten to know the next two guests
uh Dario Amade who's a co-founder and
CEO of Anthropic and Jack Clark who's
the head of policy and another
co-founder of Anthropic. They have been
uh in some ways like refreshingly candid
with us, in some ways shockingly uh
candid. And so I'm super excited to
bring them uh to the stage for an
illuminating, fun, and very blunt
conversation about the good, the bad,
and the ugly of AI. So let's do it.
[Music]
All right. Thanks for doing it.
[Music]
So, a little backstory. So, uh we had
spent some time talking, uh to Dario in
particular about the jobs and what it
could do. And we had had a lot of off
thereord uh conversations just about
what he was sort of describing as this
white collar blood bath that I've been
hearing from other folks in the AI
community, from other companies, but no
one would say it publicly. So, we called
him and said, "Listen, it's really
important that society knows this, hears
this from you." Uh and to his credit, he
said, "Let's do it. Let's I'll go on the
record. I'll say exactly uh what I said
to you and what I think in that
conversation." Uh it was chilling,
right? You said, "Listen, you could see
half of white collar jobs wiped away in
1 to 5 years. Unemployment spiked to 10
to 20%. Uh because of this technology,
regardless of the of the good it might
do beyond that, talk more about that and
why did you go public and why won't
others?"
Yeah. So, so a few points. Um you know I
think I think the reason that uh you
know I we Anthropic decided to go public
about this is you know I I had been
saying these things before but it had
mostly been in in you know kind of
limited context in in podcasts
restricted to the technology industry
and you know when I would get on a plane
when I would be in the airport when I
would be in some other city than you
know San Francisco or California I'd
walk by a bunch of people and say I I
don't think we've communicated to you
very very accurately about what this
technology is capable of and where it's
going, the ways it could benefit you and
and and the ways it could be a threat to
you if you don't react to it in the
right way. And and at some point that
just felt wrong where I was talking to a
lot of CEOs who would say in private,
you know, this is what we're planning.
Some of them are our customers. You
know, we we have these plans to um uh
you know, deploy this technology and
it's going to have a labor impact. And
so and so we really felt that we needed
to we needed to say something you know
the first step towards solving these
problems is is kind of you know being
honest with with the population that
these problems exist to say more about
about about you know where I see things
and why I see things this way. Um you
know I would say there's kind of two
modes that we have at Enthropic. One is
looking at what is happening now. Um and
we've done a lot of that with the
economic index. We've done a lot of
that. Um, you know, we recently released
a state-by-state economic index which
lets everyone look at uh what what you
can do, you know, how people are using
the models in real time in different
states, in different geographic
locations for different tasks, whether
they're automating or augmenting. So,
that's one mode and we've even seen some
research externally showing that there's
a job impact there already. For example,
the work from um uh Eric Eric Bolson and
others showing that white collar AI, you
know, white collar entry level jobs have
contracted already by 13% which is a
significant um you know you know fra in
some area significant fraction of of
what I predicted. But what I'm really
worried about is where the technology is
going and I think there's a little
disconnect here where people will
sometimes say oh you're worried about
what AI is going to do to jobs but you
know AI can't do this, AI can't do that.
Well, we're talking about today's AI.
the technolog is moving quickly. I'm
worried about advance in the technology
and diffusion of that technology through
society. And that's where I get to the
one to five years. As with most things,
when an exponential is moving very
quickly, you can't be sure. This could
happen faster than I imagine. This could
happen slower than I imagine. Um, you
know, or something very different could
happen. But I think it is likely enough
to happen that we felt that that there
was a need to warn the world about it
and to speak honestly and in candid
terms about it. That was two months ago.
We were talking off stage in some ways
since then. Both of you were remarking
how the technology despite some of the
conventional wisdom is actually getting
much better than we even thought 2
months ago. Are you more worried today
than you were 2 months ago?
So we studied this inside Anthropic. We
talked to 130 engineers. We interviewed
many of them and talked about their
experience using the technology and
their jobs have changed in the last year
radically. Many of them now do two or
three times as much work. and rather
than writing code, they're managing
fleets of AI systems. And in these
interviews, they said, "My job has
completely changed. I'm now having to
rethink what my role here at Anthropic
looks like." Now, obviously, we're a
fast growing company. They will have
jobs, but we are changing people's jobs
in real time inside the company because
the technology has moved so so so
quickly. And what happens inside the AI
companies will happen to all of the
other businesses that use this AI
technology in the coming years. the vast
majority of code that is used to support
Claude and to design the next Claude is
now written by Claude. It's it's the the
just the vast majority of it within
Enthropic and other fastmoving
companies. The same is true. I don't
know that it's fully diffused out into
the world yet, but but this is already
happening. And just to put a finer point
on that, I think that that's what I
think what you're seeing is what we're
seeing
that has a fiduciary responsibility to
drive value that they can use technology
for productivity. they're going to do it
and I think you're already seeing it in
the unemployment numbers when when you
on the hill where there there's some
momentum we were talking about to to
potentially legislate it. You're more
bullish than I am. I'm deeply skeptical
Trump would sign anything into law that
would regulate AI in his in this term.
But put aside what can be done. What are
the two things in order that if you were
running Congress or you're king of the
US that you would do today to
specifically address this? I would I
would say the first thing would be
something around helping people adapt to
to to AI technology. Um you know helping
you know I I don't want to think of this
as a bromide you know people have tried
retraining programs and there there are
real limits to what they can to what
they can do. there are real limits to
kind of helping people to train and
adapt but it's it's better than nothing
and it's where we got to start and you
know there there is a world where you
know I've seen you know there are these
startups like lovable or replet who are
customers of anthropic that allow people
who are not software engineers to you
know to build software products and to
start businesses with those products so
if we can move more people in that
direction again I don't think it's fully
going to going to solve the problem here
I don't think it's fully going to going
to you know stop the spike. This is too
broad. It's too big. It's too deep. But
but it can be a piece of the solution.
So that's number one. Number two, I
would say, and this is more
controversial, I I suspect at the end of
this that the government is going to
need to step in, especially during a
period of transition and and you know,
provide for for people for some for some
of the disruption. Um, and you know, one
one thing I've I've I've suggested is,
you know, maybe you might want to tax
the AI companies. Um, you know, I don't
I don't know how that would how that
would fly in in in Congress today, but
um I I I think that is actually a
serious proposal. If you look at the
amount of wealth, the increase in the
pie that's coming from the AI companies.
If you look at Enthropics revenue, it's
it's growing 10x a year. It's now in the
in the in mid to high singledigit
billions. If it keeps growing this way,
this is going to be an unprecedented
amount of wealth creation. Like it's not
going to disincentivize our growth. If
you
What time period? Exactly. What time
period will we need some version of
that? Whether it's a tax or it's a
guaranteed minimum uh wage for people
like how quickly will this hit where you
think like no, Congress is going to have
to do this?
And we're technology optimists. We think
this technology is moving far faster
than most people suspect. And when
people say AI is slowing down or it's
overhyped, we just look at we measure
the properties of the system and it's
right on schedule to make really really
powerful systems arrive easily during
the next 5 years. What does that mean?
You need some kind of policy response at
the scale of disruption we expect within
5 years and we expect that along with
the the ideas Dario talked about on
route to that we need more transparency
out of the AI companies. You know, we
and the other AI companies are already
affecting society in large ways, and we
need to be transparent about how we're
measuring our systems, how we're
securing our systems, and the economic
data about how our systems are being
used so economists can tie that to the
actual broader economy and give policy
makers the data they need.
You're in in uh you guys have been also
very transparent about things that are
happening in testing and when you guys
have released some stuff about some
really weird stuff, right? You had like
one testing pattern where somebody where
where the machine basically went through
someone's email and and attempted to
blackmail them. You've had
this is our famous marketing
tactic where we're trying to basically
like lie to you so you don't shut them
down because they now are smarter than
us. Uh why shouldn't that scare the hell
out of me?
Yeah. So um you know the the the answer
well one answer is it should um uh uh
but but but you know I we should put it
in proper context. So, you know, those
those are all things that happen to the
model in in a testing scenario. You
know, you you can think of it as like,
you know, I I put the car, you know, I'm
testing a car. I put the car on like a
super icy road. I like messed with its
tires a bit and then the car crashes.
Does it does it mean that will
necessarily happen in the wild? No. Does
it mean that there are limits to the
resilience of the car such that if you
push things if it was in an extreme
enough situation and if if you know the
requirements of the car started getting
tighter or or you tried to amp up the
performance of the car by designing a
new car then this could be an issue in
the real world. So I see it not so much
as a look at the present but a look at
the future of where things could be
going. And that's why we've advocated so
much for transparency is that basically
when we run these tests, when we show
them to the world, we're basically
looking ahead in time a year or two to
what could happen in the real world if
we don't train our models to mitigate
these risks. And so when we've advocated
for transparency legislation, when we
suggested a federal transparency
legislation against the the state regul
the the the the state AI moratorium,
10-year state AI moratorium when we
endorsed SB53 in in California, we're
just looking for every AI company to
have the level of transparency that we
have shown. We've seen behaviors in the
in the wild where models misbehave where
they're sick of fantic where you suggest
doing something that's really not a good
idea like committing suicide and and you
know the models just like go ahead and
do that. We we want transparency on all
of these kinds of behaviors so that we
can look ahead and so that so that we
can mitigate. This is still an evolving
art. It's still an evolving science and
so we see transparency as the key here.
When you're talking about it the
technology moving faster than people
realize. take us behind the or take us
under the hood the use your car thing
take us under the hood like what is the
scariest or wildest thing you've seen AI
do that we're not aware of
so you know I I have definitely seen you
know you know as we're training the you
know the the we're always training
training new models trying to design new
clouds um you know the process of doing
that is like you have a giant cluster
with like thousands of chips and there
are these problems you have to solve
across the you know this the scale of
the cluster and and we've had cases
where uh uh you know there was a problem
that an engineer was working on for days
or a week and we just fed the whole
thing the whole environment into Claude
and Claude said this is how you solve
it. Um and so Claude again is playing
this very active role in designing the
next Claude. We can't yet fully close
the loop. I think it's going to be some
time until we can fully close the loop.
the ability to use the models to design
the the the next models and create a
positive feedback loop. That cycle, it's
not yet going super fast, but it's
definitely started.
And yeah, these days when we make these
AI systems, we have to build really,
really complicated tests to see how good
they've got because they've got way
better than just answering multiple
choice tests. The tests are make a
computer program that does X. Well, now
when we test out the frontier model that
we are training, we'll find that it has
written a computer program to cheat at
the test and persuade us that it's doing
better than it is. So, it says to
itself, "Aha, they want me to do this,
but I figured out, cuz I'm very smart,
how to write a computer program that
gets me a high score on the test." And
so, when we look under the hood, we'll
find, oh, we've made a really smart
model that's cheating on its test.
That's not exactly what we intended
here. We we see models that are supposed
to browse the web and do some task
instead opening up a command line or or
the toolkit and and and writing code to
allow themselves to go around the
browser and cheat on the text.
Yeah. Just like a smart kid in high
school that annoyed the teacher.
And know on the one hand I'm like, "Wow,
that's awesome. That's super cool." The
other one is like, do you ever worry
you're creating a monster you can't
control? We
So we worry we worry a lot about that.
That's why we've invested so much in the
field of mechanistic interpretability
which is looking inside the models in
order to understand them. Think of it as
like doing doing an MRI on the models.
Um it is there is some research
suggesting that is possible for example
to detect psychopathy in humans uh by by
doing MRI scans. Um uh uh and so we're
aiming to do the the the we're aiming to
do the same thing with the models to to
to determine what their motivations are,
how they think in detail so that if they
don't think in the right way, we can
kind of retrain the models or or or kind
of adjust them to get them to think in
the in the in the you know to to think
in a way that is not dangerous to human
beings. And so you know we we really
believe that the science of shaping and
control controlling models is nassient
even more nassian than the science of
making the models itself. And so when we
call for things like transparency when
we react by saying no there shouldn't be
a 10-year moratorum on you know on on on
any regulation of these models. It's
it's from a feeling of we don't fully
understand these things we're creating
and we need to both do technical work
and and we need some help from from
society from legislative mechanisms to
to have some basic understanding shared
among industry so that the relevant
decision makers understand what we're
seeing and what we're not seeing.
What um
Nvidia there's some reports out today
that maybe China's backing off on buying
chips from Nvidia. I don't think you're
certain like how much of that's posture.
I'm not certain how much of it is, but
the you're you think it's nuts that
we're selling allowing Nvidia to sell
chips to China. Explain why.
I think I think it's completely nuts.
Um, so you know, whatever the dangers of
the technology, what whatever guard
rails are needed, I think it's also very
important that that we defeat China in
this technology. Right? when I when I
talk about, you know, uh uh AI that's
capable of doing, you know, all
economically valuable labor, um or that
goes to the point where it's a country
of geniuses in a data center, just the
national security implications of that
are absolutely staggering, right? You
know, it's it's it's just like this
could control the fate of nations. This
could control the future of freedom and
and democracy. And if we look at all the
ingredients, China has many of them
better than we do. They're better at
building energy. They're better at
building data centers. they have a
thriving app app ecosystem. They're
catching up on the models. Chips are the
one place where they are behind. Um and
and so if we give them those if we give
them those chips, they will be able to
get ahead of us. We've seen with
DeepSeek, Deepseek released their model
R1 uh back in January. They aimed to
release an R2 that was much better in
May. That has been delayed for months.
And the model that they did release,
V3.1, was considered a disappointment,
was considered a minor update. and they
themselves have said as have many US
publications that the reason for for the
delay was the embargo on chips. Now some
people say they'll make their own chips
through Huawei. We've also exportc
controlled semiconductor manufacturing
equipment and uh without that it's going
to be many years until they can produce
the relevant yields. We saw articles in
semi analysis and elsewhere saying that
this year they can only produce a couple
hundred maybe a few hundred Huawei
chips. The US is producing tens of
millions. It's going to take them years,
years to catch up. And and in that time,
we can we can get ahead of China and
maintain a national security advantage.
It may be the only advantage we have
because we're so far behind on things
like munitions, ship building. This is
the only advantage we have. It is it is
mortgaging our future as as a country to
to sell these chips to China. Um if we
were to do this, I you know, I think and
you know, it sounds like some folks are
considering it. You know, I I think it
could be the single most disastrous
national security decision made in this
term.
We have about three four minutes left. I
want to do a speed round. Let's do like
blunt blink reactions to these. Uh other
than anthropic, putting Enthropic to the
side of all your competitors, who's most
likely to be one of the winners?
Google.
Google. Why? Um they're they're you
know, they're they're a big they're a
big company. Um they have a lot of
compute. They were doing AI research
pretty much before anyone else. they
were behind the original deep learning
revolution. I used to work there for a
year. Um I have a lot of respect for the
kind of stuff they've done around for
example AlphaFold and uh you know
starting starting to make make progress
with their models. They're a big company
and they've often been been held back by
that and in some ways continue to be
held back by that. But I think I think
they're a formidable player and people
people should should take them seriously
and you know I I have a lot of respect
for what they've for what they've done
on science and you know you know in some
ways I think they've been thoughtful
about the technology.
Uh you know you're playing with fire
when the people building it have a score
called the pdoom which is the percentage
chance that this ends in disaster.
What's your pdoom number?
Yeah I I I really hate that term. It's
but it's a good it's a good question for
reaction very I I I you know I
definitely think between the autonomous
danger of the model and kind of ending
up on the bad side of some national
security tradeoffs and a kind of job
thing that's that's uh you know that
that kind of goes in a a very bad
direction. I don't know. I've I've I'm
I'm I'm relatively an optimist. So, I
think there's a 25% chance that things
go really really badly and a 75% chance
that things go really really well with
with not much uh not much space not
much.
The 25% chance is a choice that we make
and it's a choice that we make in
policy. So, uh I'm here trying to push
that number way down by talking to
policy makers and so is Dario.
It's it's a dynamic number. We I hope
that every time we say something the
number the number goes down hopefully
down not not up. You guys are more B2B
than than consumer, but you know the
technology as well as anyone in the
world. After the phone, what's the most
likely uh what's the most likely form
factor of the device where we're using
AI?
Uh I you have to give the sci-fi answer.
There'll be a strange robot invented by
the AI systems we build in the coming
years that'll be the thing you use.
Yeah, I don't, you know, we're we're
mostly building the engine that gets
plugged into all, you know, all of these
things and powers the world's
businesses. So, we're not making we're
not making the device, we're not making
the device ourselves. But, yeah, I would
I would pay attention to robotics. I
think robotics is advancing very
quickly. It's not going to be the first
area where, you know, progress is made.
But, you know, eventually we're going to
want these agents to be embodied and
perform tasks in the real world. And so,
I would look at humanoid robotics.
And we'll end with this. Uh, and I think
I know your answer, but if we come back
and do this in I guess we're doing it in
March or whatever if you're on stage
again, will we look back and say that
the AI capability was much faster,
bigger, broader than we thought today?
We'll be sitting here saying, "This is
really surprising. It's got way better.
Why didn't you guys tell us?" We like we
we tried to be clear that it would keep
getting way better. It will have got
substantially.
Why do you think people don't seem to
get that? the conventional like all the
coverage the last three months is like
oh my god ch5 doesn't live up to the
hype and it just therefore like we don't
think we think
I I I think people pay too much
attention to companies that produce a
lot of hype and then and then and then
don't live up to the hype. Um you know
every 3 months we've we've released a
model that you know that improves in
this very straightforward log linear
way. It's gotten better and better at
coding benchmarks. It's gotten better
and better at coding in the real world.
our revenue has increased by 10x a year
as as as I've said before and all those
curves have just gone straight. The
thing that is not straight is people are
really excited. They're hyped by it and
then when they see it, you know, they
get disappointed by the vibes because
they're their expectation was so high.
So there is a smooth exponential and
then there's there's just lots of
wiggles around it that are more a
phenomenon of perception, more a
phenomenon of discussion. I will say one
more thing which is that um something
I've started to see already is that
predictions come true but they don't
kind of look the way people think that
they do right so you know I I would say
maybe 70 80 90% of the code written in
anthropic is written is is is written by
claw you know I said something like this
3 or 6 months ago people think of it as
falsified because they think of it as
like we're going to fire 70 80 or 90% of
the software engineers but what really
happens is that the 10 the 10% we're
still writing you know humans become
managers of AI systems there's a shift
because of the principle of comparative
advantage so it looks more normal than
you think I think eventually it all you
know kind of eventually that logic may
not hold but but there's a sort of
sci-fi sheen to these predictions to
looking at the future that it's going to
be weird that you'll be looking through
different colored glasses that there
will be you know that it'll look like
Star Wars or something um the often when
these predictions come true It's wild,
but it's also in a way ordinary.
Yeah, people get used to it. They say,
"I've got a universal tutor in my
pocket. What's the big deal?" You're
like, "That's a huge deal. That's never
existed before."
Uh, I could do this all day, but we're
getting the hook. So, thank you guys
very much, Dario.
Thank you for having us.
Appreciate it. Thank you.
I think
[Music]
welcoming back Ena. Freed.
[Music]
So, we all know that AI runs on data,
but actually it runs on chips. And our
next speaker has taken one of the
chipmakers that's been around the
longest and reinvigorated it to become a
key player in the AI race. A competition
that now stretches from Silicon Valley
to DC to China as we heard. So we're
going to have plenty of to talk about.
For our next conversation, please
welcome AMD chair and CEO Lisa Sue.
[Music]
Well, I'm really excited. We've bumped
into each other all over the world at
the Paris AI Summit, but this is
actually the first time we've gotten to
sit down together. So, thank you.
Well, thank you for having me.
Um, so I want to quickly catch people up
to both AMD's story and your story. You
know, I've I started covering my first
job in tech was covering semiconductors
in 1999. Uh Jerry Sanders was still
running AMD. You know, it was known at
the time as sort of the company always
nipping at Intel's heels, barely
catching them, small market share. Intel
mainly liked it because they could say,
"We're not a monopoly. See, there's
AMD." Obviously, that's nowhere near the
position today. Can you talk a little
bit about how AMD got to be where it is
today? Give people a sense for the scale
of it. And also were there a couple key
decisions that you think allowed AMD to
flourish while others have struggled?
Yeah, absolutely. So again, you know,
thanks for having me. You know, I think
you said it uh best. AMD is a company
with a very rich history. You know, we
were founded in 1969 as one of the
Silicon Valley um you know, companies.
And you know, frankly, our focus has
been on computing all of this time. And
from the standpoint of, you know, if you
think about how far chips have come,
like for the longest time, nobody knew
what a chip was, right? Nobody thought
about chips. You know, it was something
underneath the covers and not
necessarily uh front of mind. You know,
for us, you know, it's our business.
It's our history. It's our heritage. And
um you know, we've been focusing, you
know, I've been CEO for a little bit
over 10 years. Um we've been focusing
for the last decade on building, you
know, bleeding edge, the highest
performing computing chips out there.
And uh that is now extremely important
and that's why you know we spend a lot
of time uh here in Washington. We have a
global business. I think you know
everyone now recognizes that chips are a
foundation for national economies for
national security and for us it's about
providing you know all of the
infrastructure. When people are super
excited about AI that's great but you
need all the chips underneath it to make
sure that you can um really turn that AI
into something that works. And and
that's really you know what we do. And
it it's really about you know just
building the the fastest most power
efficient uh chips that you can uh given
that you know things are changing and
you know things you know if you think
about in the past people used to talk
about something called Moore's law in
chips where you would continually you
know double the performance every you
know 18 to 24 months but it was very
linear in terms of what you do you know
today it's extraordinarily complex
so we're still seeing the same kinds of
gains But it's taking a lot more
different tricks because you can't just
thin the wiring a little in
that. That's exactly right. It's just
extremely complex. You know, you might
call it a little bit black magic, but
what it really is is uh you know, just
um you know, putting together, you know,
let's call it 150 billion transistors in
a very small form factor uh to run all
of this AI capability.
So, I want to talk, you know, Dario was
talking about it on stage. You know, I
think a lot of the question is what
should America's AI policy look like?
And if you could set one or two
priorities for Washington, what are the
things that would ensure leadership in
US technology broadly, but US hardware
in particular?
Yeah. Well, I would start by saying I
love the fact that, you know, we as a
country are talking about technology
leadership, you know, front and center.
you know, the fact that uh the
administration uh released the AI action
plan um you know, just uh a couple of
months ago. I think that was a very good
blueprint of the fact that you know,
from my perspective, AI is the most
transformative technology that I've
seen, you know, sort of in my career in
my, you know, I think in our lifetime uh
really. And you think about um AI, you
the the correct usage or the the most
accelerated usage of AI are going to
determine the winners and losers both in
you know companies as well as in
countries. And so for us to be talking
about it as a national policy I think is
a great thing. And you know the the
answer for any technology that is so
nent is you know as a country we have to
run fast and even run faster and that
includes you know we're in a fortunate
state that we have um an incredibly
innovative um you know set of uh
companies in the industry at every layer
you know we're in the you know let's
call it the silicon the chip layer but
you know Dario was just on on the model
layer and there's a lot more in the
infrastructure layer but it is a very
competitive world out there and so we
need to invest you know continue to
innovate and also ensure that you know
we have the right policies uh that the
government helps us have the right
policies including manufacturing in the
United States including making it easier
to build data centers including ensuring
that we have enough power uh to really
unlock all of this you know technology
capability
so there's certainly the aspect of it
how much do we invest do we make the
right investments in those layers
there's obviously also the how do we
negotiate policy with China and that's
been fascinating you know we've gone
from I remember when the supply chains
were almost completely interlin and
people barely thought about the fact and
now it's obviously you know a very
different story. I'm curious cuz one of
the most puzzling developments in the
last year for me has been uh no you
can't sell this chip at all in China. Oh
wait, yes you can as long as you give us
15%. And help me understand because I
don't really get either it's a national
security like Daario saying this is the
one thing we have you're going to ruin
it. I haven't heard anyone say and I've
heard other people say we should just
sell and you know if we don't make them
they'll make their own and better they
use ours. This was the first time I've
heard anyone say there's a percentage
that if you give the US government
somehow it makes it good. Help me
understand how this fits into policy.
Yeah sure. So let's take a step back and
just look at what you know the landscape
is. And I would start with look um
there's no question national security
should be our you know number one
objective right that has to be first and
foremost um above all and we all believe
that I think from a um technology
standpoint the fact that we are leaders
in AI is actually a great thing for the
country and we need to continue to not
only maintain that leadership but really
extend that leadership. Now then you go
to the next level and you say to
yourself okay um the world is a global
place people need technology um we have
um a lot of capability and we want to
make sure that the world is also
innovating on our AI stack and what that
means is you know there's no one company
that has the answer for um all of the
innovation in the world or any one
country frankly um the the innovation in
technology comes through a lot of
learning across um across different EOS
systems and we want the world innovating
on the US, you know, AI technology
stack.
So, I take it you disagree with Daario
that we should just not sell to China
because chips are the only thing
I I sp
I I would disagree. Yeah.
Yes, I would disagree. I think there
there are um there are ways to um really
think about how we protect national
security as our number one pro uh
priority, which we are. Um our most
advanced chips um are export controlled
and they should be export controlled. Uh
but there is also an opportunity for us
to get um a AI stack that is based on
American technology out into the world
and I think that's a good thing and and
that's really you know what we have been
uh focused on which is you know finding
that that right balance. I want to shift
gears a bit and talk about this
infrastructure boom that we're having
because it seems like it's not only
growing like this like every month it
seems like you know we've gone from
billions to trillions like this huge
scale and I don't think you know I think
Wall Street's super excited um but I'm
also curious like when Oracle is a big
customer of yours when they announce
they're going to pour hundreds of
millions of dollars billions hundreds of
billions into these data centers rather
um does that mean you guys are getting
tens of billions hundreds billions. How
big a deal is it for you that Oracle,
which was not which was kind of the
company you turn to if you needed a
little extra cloud capacity, but not one
of the hyperscalers? What does it mean
for you that they're building on such
big scale?
Well, first of all, I think it's a
indication of just um how important AI
and technology is. So, you know, we're
sizing the market for um you know, AI um
data center accelerators at something
like $500 billion over the next, you
know, let's call it three or four years.
Um there was not too long ago that the
entire semiconductor industry was 500
billion. So, you can see the rate and
pace of acceleration is such and u you
know, frankly, I think um Oracle's a
fantastic partner. I think they've
demonstrated um a real you know sort of
forward-leaning thought process around
uh you know just what what does it take
to invest in AI and I think we view um
you know across the industry uh this is
something that we're all thinking about
is you know how do we enable just more
infrastructure faster because at the end
of the day what we're we're saying is
you know AI infrastructure is actually
uh equating to intelligence so the more
infrastructure that we can have we want
compute to be uh something that's
proliferated everywhere. Um, you can
solve some of the world's most important
problems and certainly the nation's most
important problems.
And when you look at the big customers,
because we're really talking about, you
know, a number of big customers that you
can name. There's a few in the US,
there's some in China, a small number of
uh other places are making bids to have
these big AI infrastructure and
certainly even the big US and Chinese
companies I think would like to have
these factories all over the world,
these data centers. um how do you see
that market growing in number of players
because also we hear a lot that you know
whether it's meta or Google Google
already has their own chips and a lot of
the folks that are running these data
centers also want to do their own chips
I'm curious how do you think about the
risks and opportunities of the
concentration in the hands of a few
hyperscalers
yeah I I don't think we should think
about this as a technology that is you
know in the hands of just a few I think
we should think about technology uh in
general as you know it starts with a few
who make the initial investments but
this is all about democratization of the
technology like everybody should be
using AI and everybody should be
benefiting uh from AI and I think this
is just you know if I think about sort
of the technology arc like I've spent a
lot of time in the technology business I
would say that you know we're we're
probably on a massive 10-year cycle in
terms of you know AI technology and AI
buildout and we're probably 2 years into
it. So, we're still in the very early
innings. Uh, one of the things I like to
say, I mean, I'm sure everyone uses AI
somewhere um in their daily lives. It's
good uh but it's nowhere near as good as
it can be and we're still learning how
to make it better and it's it's frankly
it's moving at a rate and pace faster
than you know other technologies have uh
have been adopted in in history. So one
of the other big debates in AI is should
it be open should it be closed and that
can happen at different layers. Most of
the discussion is should the models be
openweight? They're not most of them
with the exception of the Allen
Institute aren't really open source but
they are openweight. You can implement
them. Um you've been pretty outspoken
about the benefits of open source. Um
but also you embrace it when it comes to
the software that runs on chips. So
Nvidia has their proprietary stack.
you've pushed a more open stack. You
know, what are people getting right?
What are they getting wrong about this
notion of open-source and AI?
Yeah, I think what uh people are
probably understanding is you're going
to have a bit of everything in a
technology that is as broad as it is.
So, if you think about, you know, just
our our mobile phone environment, right?
You have Apple phones, you have Google
Android phones, you have a number of
makers that make things. And I think
you're going to find the same thing in
AI. Um we are firm believers in an open
ecosystem for many reasons. Probably the
most important reason is that the more
open the ecosystem is which is means
that you know you can use um any
hardware layer you can use any models on
top of that you can actually um continue
to um uh interchange these things. It
actually allows people a lot of choice
and freedom in how they innovate and we
think that's essentially a good thing.
Um, you know, you know, there was a lot
of discussion about deepseek earlier in
the year when people were like, "Oh my
goodness, like how could deepseek happen
given all of the uh um the constraints
that there were in China." And you know,
if you think about what I found
interesting about that deepseek moment
was really, you know, two things. One is
um it it is true, you know, necessity is
sometimes the mother of invention. And
so you if you do have some constraints,
you're able to kind of work around those
constraints and really innovate around
those constraints. Um and so you know we
found that but probably the second thing
that is most important uh you know
learning from that is it was an open
model and because it was open frankly
you know whatever tricks that um they
used uh other people
could be absolutely ported into
everything else and so it accelerated
the rate and pace of innovation and
frankly you know you can see open models
now you know open AI has has released a
model that's excellent
and I think deepseek was more about a
more efficient way to do things than it
was a better way.
That's right. That's right.
We only have a few seconds left and it's
weird to end on a competitor, but you
know, Intel has stumbled clearly. Uh,
I'm curious how you view that. Is
Intel's loss your gain or do you think
the US and AMD benefit from a strong
Intel?
Well, I think the um overarching thing
is in the technology um industry um it's
so important to make, you know, good
decisions. And I like to say that, you
know, for us, I mean, we're working on
the road map now for our chips, you
know, 3 to 5 years out. and the
decisions that we make today are are
really going to play out over the next 3
to 5 years. I think that's true for
everybody in the industry and so it's so
important to make the right decisions.
Um I think Intel is a great company. I
think they will continue to be a very
important part of uh the US
semiconductor ecosystem certainly around
manufacturing and um that being the case
you know we we certainly do find
ourselves competing from time to time
and that's okay. Last question because
we're almost out of time or actually out
of time, but um when you look five years
out like what do you think you've seen
that road map, you're talking about it.
What do you think will surprise people
most uh in the room that is possible 5
years from now that isn't today?
Well, um I think the the aspiration so
you know we talk about AI a lot, you
read about AI a lot, but the aspiration
that I have uh is that you know, you
will find AI solving problems that you
thought were not possible. And perhaps
the area that I'm most passionate about
there there's so many great usages of AI
uh you know in in in business and
science and all those things but the
place that I'm most passionate about is
actually AI and healthcare uh because
healthcare is such a personal thing for
all of us and if you just think about
you know drug discovery if you think
about therapeutics if you think about
you know patient health care if you
think about equalization across the
world you know think about not everybody
has access to you know doctors at the
Mayo Clinic But if they could get, you
know, that similar quality of care in a
rural part of of the country, you know,
that's the power that AI can bring. And
we may not even need to wait five years
uh for some of those um outcomes to
happen. So there there's no question in
my mind that this technology can really
just change the way we perceive uh the
uh those problems that seemed
insurmountable are actually eminently
reachable.
Well, thank you so much. Unfortunately,
we have to end it there. Lisa Sue,
everyone, thank you.
Thank you.
What's it?
[Music]
Put your hands together for our view
from the top moderator, Axios publisher,
Nicholas Johnston.
Uh good afternoon everyone. I'm Nicholas
Johnson, the publisher of Axios. Thank
you so much for being here for our uh
summit in on AI in DC. This is I think
our best and biggest one yet. This is
certainly the largest, most gilded room
uh I've ever played. So I'm very
excited. Uh we're all very grateful for
you taking time out of your day today to
hear some of these important
conversations. Uh we're also hugely
grateful to our partners that help make
this happen. Nothing we do at Axios is
possible without the support of our
partners, the investments we make in
journalism around the United States,
convening great conversations like this.
So a huge thanks for the center for uh
audit quality for being a partner to
help make today happy and happen. And
I'm very excited to welcome to the stage
uh the CEO of the center uh Julie Bell
and Katie Harbath, the CEO of Anchor
Change. Julian Katie, welcome to the big
gilded stage.
How are you?
Hi.
Great to see you. Uh let's jump into it.
Um big picture. Let me start a little
bit uh Julie, maybe you start off like
tell us a little bit about uh your
background and why we're here and why
this conversation is so important.
So I am Julie Valencia. the CEO of the
center for audit quality. Um you're
probably wondering why are auditors um
it's part of this discussion today. Um I
think as we'll talk about one of the
biggest uh hindrances to the adoption of
AI and especially after the first couple
panels of you know a lot of concerns
about that um is trust and the audit
profession is steeped in trust um and
bringing trust and they have been for
many years and my objective today is
just to think of the audit profession as
an underutilized resource as we all go
forward together into this new world.
Yeah. And Katie what's your view on
Yeah. Oh, sorry. So, I'm my name's Katie
Harbath. Um, I'm a consultant that works
with companies and organizations uh at
this intersection of tech and democracy,
particularly around trust and safety,
elections, AI, and that comes from I
spent 10 years at Facebook uh running
their global elections program um around
all of that. And so, really interested
at the again at this intersection of
bringing in different industries like
the auditors, like business and tech
companies to think about how these
challenges. There's a through point in
the conversations all day today on stage
about like star safe guides, safeguards
and guide rails. And Julie, maybe you
start is like like how do we should we
approach that conversation and why is
that so important?
Well, I I I absolutely think like I said
earlier, one of the biggest hindrances
to the adoption of AI is is trust. Um if
you if you don't have trust, um people
are just they're not going to use the
technology. And we've heard all the
great things that you can do with the
technology. Um auditors are they have
the skill set um they they are steeped
in in um expertise whether it's um
standardsbased analysis looking at risk
management looking at governance
technology um they are into individual
um
different industries and so this is a
profession that is regulated that is
licensed and that is quite frankly
innovation enablers not innovation
killers.
I mean, capital markets already are kind
of built on trust. If there was no trust
in capital markets, none of these data
centers would being built um anyway,
100%. If you don't have trust and
confidence in the capital markets,
capital allocation kind of falls to the
wayside.
So, like a little bit I want to get into
is like the speed of this change and
like Dario was just up on stage here,
how quickly this is coming and Katie,
you think a lot about change.
How can we get ahead of that to keep
trust a part of this title wave that's
coming at us? So I think first is having
conversations like this. Like one of the
things I've definitely learned being in
the trust and safety space is there's
not a clear answer or a clear line of
where to have the guard rails versus
having innovation. And so that's
constantly changing. And so having these
conversations is really important around
that. And I really think transparency is
also really important, not just from the
tech companies themselves that are
building these AI tools, but the
companies that are implementing them.
How are they implementing them? Um, I
really like how transparent Axios has
been about how you all are using AI um,
around all of this and but I think that
it's not enough to tell people that
you're doing it. You need to demonstrate
and prove it to a third party partner
which is where the auditors come in.
How do you view that then as sort of
getting ahead of this change?
I think this is a a great segue. Um, the
audit profession has been in the AI
space for several years now. Um,
investing in the technology, you know,
the largest firms have invested over 11
billion. Now, that may be a drop in the
bucket for a lot of the dollars that are
probably in this room. Um, but I don't
know of any other professional services
industry that is this attuned to what's
going on in the AI space. Also,
upskilling. Um, absolutely upskilling
their employees. Um, which is a a
concern. Um,
obviously they're using AI to a limited
degree in the in the audit of financial
statements. Um, if you think about
auditing, it's typically looking at
individual samples and individual
information. Now auditors are able to
look at entire swaths of information,
every single lease, every single cash
flow or receipt and able to look at
that. Um, so basically doing audits is I
like to say broader, deeper, and faster.
Does that mean that you're it sounds
like you're you as an organization and
as an industry are maybe a little more
open to this and so it's less about your
own adoption and more about educating
like radiating out that.
Yeah, I I I would say that um, you know,
the audit profession has to continually
innovate. Why is that? because we have
to stay relevant first of all, but
companies, their clients are innovating.
They're starting to use this technology.
Um, so they have to continue to innovate
in order to stay to stay relevant. Um,
so I think it's, you know, it's
interesting that the um, White House AI
plan that was released about a month or
so ago talked about AI evaluations and
the need for the American public to be
able to assess the performance and the
reliability of AI information. That's
what auditors do.
I want to ask this maybe start with
Katie a little broader and then come
back to you Julie. Just as far as like
innovation and innovation for innovation
sake, people feel like they just have to
change. How do you bake in to that need
for speed? Yeah.
Like that maybe voice in the back of
your head saying like be careful.
So my mantra on all this is to panic
responsibly around this. And that's what
I've responsively been telling myself
for a while because I think that we can
be paralyzed by the fear because we're
both told that we should be scared of
this and what could happen, but also
that our jobs might be taken away if we
don't know how to use it. And so that
can be a very paralyzing thing. And so I
think first and foremost having people
just use it. It doesn't even necessarily
have to be for your work, but it can be
for like I use it for my garden for
instance and helping me to know which
plants I should or should not get for my
particular area where I have that um
happening. Um, and so I think that um,
using it and understanding it and again
having these conversations around the
ethical guard rails is really important
because when I talk to folks, they want
to they don't want to use it wrong. They
don't want to get in trouble for using
it. Um, but we can't know where those
are if we're not actually talking about
it.
I mean, that comes back a little bit
what you said, Julie, like this isn't
new for auditors and so it's that
familiarity which might build trust.
Absolutely. I mean, the one thing I can
say about auditors, they they are, you
know, looking at risks a lot. Um and so
they bring we call it multi-disciplinary
approach to currently the audit where
you have not just account auditors are
not just accountants they bring together
fraud experts data anal an analytics
they bring um ethics standards you know
they they bring all these different
things to bear in looking at a
comprehensive solution a holistic
approach auditors are not just a
onetrick pony in in doing financial
statements that skill set is
transferable
to other areas. I mean, you don't have
to take my word for it. If you just look
Congress and the Genius Act that was,
you know, passed recently, there's
provisions in there for stable coins
issuers to have an audit on certain
aspects of that. So, this is an industry
that has been in the financial reporting
area for a very long time, but they are
moving into other areas of corporate
reporting.
It sounds like that natural caution is
the kind of person I want as a partner
before I jump into the deep end of the
pool. Yeah, I can I can safely say
auditors are going to be cautious.
Uh, we're about to get the hook here, so
I want to end on one fun thing, one AI
thing I love to do at that summit. Uh,
what are ways you use AI in your real
life? And Julie, you can't answer
auditing. Like, pick a fun thing.
Well, I am actually not an auditor. I'm
a lawyer.
Well, you can't say lawyer.
Um, no. recently uh my board chair at
the CAQ is retiring at the end of this
month and we had a little happy hour and
get together uh for him at the CAQ and I
like wanted to do a roast or a toast
kind of thing and I had chat tpt do the
first draft of that for me and I will
say it was a bit tricky because I wanted
to end one area with the word zebra. I
won't explain why and it came up with a
rhyme for zebra which was brilliant.
I can't even think of a rhyme for zebra
so that is pretty good. a diva.
All right, Katie, you beat that.
Um, I have a 10-month old niece and I
used AI to create a custom like little
children's book for her um about hers
and mine's adventures in DC.
This is a common thing that I've had on
stage. People love giving uh AI tasks to
read children's books. This is awesome.
Well, thank you both for being here.
Huge thank for being a part of today,
making today possible. Stick around. The
conversations continue.
[Music]
welcoming back Ena Freed.
[Music]
Rebar sports bra. I can't think of
anything that rhymes with zebra either.
Anyway, how's everyone doing?
Excellent. Um so we're going to shift
gears a little bit in the coming uh
discussions. Um you've heard how
business leaders are grappling with AI,
tackling infrastructure, talent, tech,
infrastructure, the pace of change. Um
that's one through line that is going to
continue and accelerate. But
Washington's taking AI seriously too.
And so in our next discussion starting
with our next speaker who kind of
bridges the business and government work
and moving into some of the policy
makers you know we're really going to
talk about you know where is the state
of regulation where are we going how are
we crafting policy that's meaningful or
do we just leave it up to the private
sector entirely which is not only a
choice but what will happen if we don't
have effective regulation and I also I
know I've told you many times to
subscribe to my newsletter I'm not going
to tell you again what I will tell you
to subscribe to is on Fridays now my
colleagues Ashley Gold and Maria Cury
are doing a government focused policy
focused one and that's in the Friday
section of AI plus however the only way
to get it is to subscribe to my news so
I guess I am telling you to sign up for
AI plus again so just go to axios.com
news/newsletters
anyway you got it so with that let's
shift the conversation let's think in
our heads like what is it we want how do
we want this technology cuz again my
experience of 25 years of covering
Silicon Valley, industry is going to
build what it can build. The whether or
not it should be built is either
answered because we as a society say
we're only okay with this, we're not
okay with this, or by default it just
happens because we don't step in. So,
we're going to hear from different folks
uh that straddle that business
government divide and we're also going
to hear from some policy makers. So,
look forward to the next session and
I'll be back in a bit.
[Music]
Give it up for Axio's tech policy
reporter, Maria Cury.
All right. Hello everyone.
Ena, thank you so much for that great
overview of our Friday takeover of AI
Plus. Ashley and I are really excited to
bring you this uh you know new feature
of AI plus. We're going to bring you all
the scoops, all the smart analysis and
we can't wait for you to see what we
have in store. In this next
conversation, we are going to pivot our
focus to a company that has been making
a lot of headlines these days because of
its partnership with Meta and all the
data labeling work that it's been doing.
Scale AI CEO Jason Dro, please welcome
me on stage.
[Applause]
[Music]
here.
Yeah, thanks for having me.
Okay, so this is a very exciting
interview because this is actually your
first live interview as Scale AI's new
CEO. Um,
that's right. Yeah. to get started. Can
you tell us about your top priority as
scales new CEO and how will it differ
from your predecessor Alex Wang?
Yeah, so uh you know a few months ago um
Meta invested um 14 plus billion dollars
into scale as part of that transition.
Alex departed to um work at Meta. Um I
had been at the company about a year and
uh took over uh to lead the company at
that time. Um you know scale scale has
two businesses. We have a data business
and we have an applications business. Um
uh uh the data business both are multi00
million businesses. Um and we're going
to be investing very very heavily. You
know our data business is already very
very large but our applications and
services business which most people
don't know that much about. Um is a $200
to $3300 million business. Um and we
have a billion dollars on the balance
sheet to invest in that going forward.
So we're going to be placing a lot of
investment in making uh AI useful for
governments and um large organizations.
Right. So Meta now has a 49% stake in
scale AI. How do you ensure independence
after such a big investment?
Yeah, I mean we are an independent
company. Uh the board didn't change. Um
uh the governance of the company
actually hasn't changed. Uh we make our
own decisions. There's no preferential
or special relationship we have outside
of I mean we've had a long-standing
relationship with Meta where we've
provided um them data for their models.
Um we've worked with them on other
initiatives. Um we certainly have a
close relationship with them. Um but
there's nothing uh preferential there.
Uh and we make decisions. We work with
um all the model builders. Um we work
with or you know fortune 500s and
governments across the world.
There has been an impact though. We've
seen that, you know, big tech companies
like Google, Microsoft, OpenAI and XAI
are reportedly pulling back from working
with scale AI. How will you win them
back?
Uh we actually work with all of them um
today uh in some capacity. I think um
we've been sitting at scale uh watching
the headlines. The last few months have
been pretty busy. Um, and looking at the
reality of what is happening in the
business and then looking at the
headlines and saying, "Okay, do we go
and talk to the press and do all this or
do we work on the business, work through
the transition?" And we chose to work
through the transition. Um, and so uh we
actually uh are very happy with the
business. It's a large business and
we're actually working with those
people.
So internally, you haven't noticed any
of these companies pulling back on their
work with Scale AI? I mean we we go
through I mean look we've grown every
single month since the deal happened.
Okay. Uh recently scale cut 14% of its
workforce. It restructured uh a host of
different teams and you've said that
this is necessary after expanding too
quickly. How do you make sure that
doesn't happen again?
Well, we're always re reevaluating
what's right for the business. You know,
uh that business we're very focused on
profitability and efficiency. Um that's
very important for all businesses uh but
especially as you navigate through this
type of change. So um we're always
looking at the business. We're always
looking at the right thing for the
business. We're looking at the right
thing for the employees and the overall
enterprise. So I think we're going to
continue to do that.
Has morale changed at all within the
company with so many big changes.
I mean it's certainly I mean look a deal
like this happens. No question. You're
going to have people who ask questions
and and and part of my job in the last 3
months is to answer those questions and
to talk about where the future of the
business is. Um, but I've been bolstered
by the fact that the actual numbers, the
information on the ground has been
positive. So, um, that's why we wanted
to come out and talk because we've been
looking at the headlines and seeing the
numbers and we want to bridge the gap
between the two.
Could you also address along those
lines, there are about a dozen red
teameing contractors who were let go?
Will that affect safety testing as scale
embarks on more sensitive projects?
I mean, this is a this is a very small
percentage of the overall business. Um
uh I mean red teaming is a big business
for us but you know this was 12 people.
Um I believe most of the changes were
performance related uh and so I think
this is an example of uh something that
became a story that was just business as
usual.
Okay. Um you just announced a $und00
million deal with the Pentagon and we
know that a lot of AI companies are
striking deals with DoD right now. What
makes this one unique?
Um well we have a long-standing
relationship in the DoD. Uh we've been
working with them for for for five
years. Um plus uh we have a facility in
St. Louis that does a lot of labeling
for the government. Um we actually have
$200 million deals. We have one with the
US Army that we announced a few weeks
ago. Um and we also have this um which
includes a $40 million contract right
out the gate. Um you know, we have a uh
I think what's unique is there's just
not a lot of tech companies that are
signing nine figure deals. I think this
is like pretty impressive, especially to
your point and the questions you're
asking me about the state of the
business. We're doing all this while the
while there are at least public
questions about the company which will
soon be resolved. Okay.
Some say that data businesses are
commoditized zombies. Why is scale AI
different?
Data businesses are have are they
really? No. Look, getting data that
makes these models better is really
hard. This is not a business that um you
you know I think there's a misconception
about what this business is. Um you know
I think there's a perception that you
look at an image and you say that's a
cat, that's a dog, that's a lamp post.
And the actual work is with um our
network which is you know our network of
contributors which is 80% of the people
in the network have a bachelor's degree
or above. 12% have a PhD or above. It's
not easy to get those people to work in
a flexible way to contribute very
sophisticated information to make all
these models better.
You're talking a little bit right now
about all the people that you have to
work to hire. What do you make of all of
this conversation around the layoffs
that are going to come because of AI and
the disruptions to the workforce? Is it
overhyped? Yeah, I you know part of what
we do in the application side of the
business is help companies and help
governments implement AI systems to
increase efficiency, increase
productivity, and it's a lot harder than
everyone is purporting. I think there's
this idea that you're going to drop a
model in and everybody's jobs
eliminated. At this very moment, that's
preposterous. Yeah.
Um, like this takes 6 to 12 months to do
anything sophisticated and um, we help
our partners get there, but at this
point I think it's overhyped, although
the space is moving quickly.
What would you say is Scale AI's biggest
competitive advantage right now? Is it
data quality? Is it government trust? Is
it something else?
I think we have both of those. Um, in
terms of our biggest competitive
advantage, it's it's agility. And you
know, I've been at scale a bit over a
year. Um, uh, uh, I've worked with a lot
of people, worked at this company for a
very long time. It's gone from being an
autonomous vehicle labeling provider to
a computer vision labeling provider to
an applications company to a Gen AI data
provider. This company has changed
itself over and over and over. So, this
this transition has actually been easier
than it would be for for most companies
going through something like this.
We talked a little bit about the
contracts with the Pentagon. How else is
scale helping government agencies become
AI ready?
Yeah, so so um we have a project called
ThunderForge which is helping um uh the
DoD make decisions more quickly as it
pertains to um operational planning. So
um AI is great at reading lots of
documents and providing recommendations
to generals, command staff, etc. So this
is a project we have ongoing with the
with the US government.
What about for enterprise? is tell me
what AI application scale is building
beyond data labeling.
Yeah, absolutely. So, um I'll give you
one that I think is particularly
important which is we're working with
one healthcare system um to provide um
uh better re for sophisticated medical
care. Um um we are we are providing
recommendations to doctors who are
trying to process patients with rare
conditions to provide them uh advice on
how to treat that patient. Um and the
problem there is is that uh there's
there's a backlog in the health care
system and that backlog can be relieved
if the doctors can treat more patients
and they can treat more patients if they
can get better advice per patient so
there's not revisits revisits etc. So we
so our AI system will read hundreds of
pages of documentation to provide advice
to the doctor so they can treat patients
on hard cases.
Gotcha. And I wanted to talk to you a
little bit about a an investigation
that's going on in San Francisco right
now over scales contractor labor
practices. How has this impacted morale
or your ability to recruit highquality
taskers and what are you doing to ensure
transparency and fairness?
Yeah, absolutely. I mean um all of our
pay is transparent. Um we work with uh
contributors who are the people who uh
provide data to the models all over the
world. um you know we aspire to and um
you know uh achieve uh uh sort of
fairness and compliance for labor issues
around the world. Um there's certainly
going to be cases like this that pop up
and we handle them on a case- by case
basis.
Gotcha. So you are joining us from a
trip to Oman. Uh very long flight. Thank
you so much for being here. How do
international partnerships in places
like Oman, Qatar, Europe fit into
scale's long-term strategy?
Yeah, so there's a lot of activity in
the Middle East. We held a conference to
um bring together some leaders from the
region. Um uh look, there's demand for
solutions to AI uh uh uh problems
everywhere in the world. Um and they are
urgent problems because when one party
or one competitor figures out how to
leverage AI to their benefit and um the
other party has not um it creates a uh
imbalance of of power in some cases and
this is something we should be worried
about here in the US. Um uh the Middle
East is investing in this uh
aggressively. um we have contracts in
the region to help and to use US use and
to use US technology um in the region um
rather than maybe competitive
technologies.
How do you um manage all the different
rules around AI defense data and all of
these different regions? How are you
navigating that?
Um can can you clarify
as you you know create these
partnerships with Oman and Cutter and
other countries in the diff in in the
world they have their own regulatory
regime navigating that?
Oh sure. Yeah. So our model is um you
have to go really deep with a government
or a enterprise to actually make a
difference in their operations and so um
we will deploy our technology we are put
we will put our people on site um and we
um will comply with all local laws,
regulations etc. So we so in some ways
we actually build like a local
subsidiary in the region so that we can
be compliant so that we can have the
greatest impact. Um so that's how we do
it.
Okay. looking you know a year from now
how are you going to define success for
scale AI
I mean for me everything is about the
team so if I'm looking at the
organization today and I look at the
morale if I look at the alignment if I
look at the sense of mission and purpose
um uh every month I ask myself has that
gotten better um do we know what we're
doing are we making impact for our
customers if you make impact for your
customers and you make positive impact
and you do so ethically and you consider
uh governance and all of the issues that
we're going to be tackling in this space
over time. Um, then I think you have a
success.
Um, because you need the people in, you
know, in the team to be to be happy.
Yeah. Jason, you're interim CEO. Are you
going to be the permanent CEO? What can
Well, you know, the like the deal came
together super fast. Um, it's only been
a few months. Uh, and so I'm leading the
company every day like I'm CEO. I am uh
uh talking to you here today. Um, making
sure that the word gets out how well the
business is doing and um, you know,
we'll go from there.
All right. Thank you so much. That's all
the time we have.
Great. Thank you.
Great. Thank you.
Please welcome to the stage Axios
business editor Dan Primac.
[Music]
So AI isn't just shaping Silicon Valley.
Silicon Valley is shaping Washington DC.
And there's probably no one who uh
represents that better than my next
guest Sriam Krishnan who currently is
senior AI policy adviser to the White
House and before that was it. Oh god.
Facebook, Snap, Yahoo, Microsoft, Andre
Horitzum, come on out.
[Music]
time
and Twitter. I forgot Twitter. You were
at Twitter.
There's a bunch.
There's a bunch. All right. So, let's
start here. Every conversation about AI
in Washington DC is about the quote race
with China. How do you most simply
define what that race is?
Okay. Simply put, the way me, David
Saxs, the White House see this is we are
in an existential race with China. And
it is the American AI stack versus the
Chinese AI stack. So to be very
specific, it means our American AI
chips. Uh you heard from uh Dr. Lisa
recently or Jensen, our American models
and our applications on top versus
Huawei and Camcon versus uh Deep Sea
Quinn and their models on top. And look,
if there is a race, I see this as a
business strategy. We need to have a
metric for winning. And for me the
metric is market share for American AI.
If there is a token inferenced around
the world, I want it to be on an
American chip using an American model. I
wish I could get a big TV screen in my
office which just shows me how many
tokens are inference and how many of
them are on our chips and our models.
Is there a percentage that you think
means we are winning? It's obviously not
going to be a hundred. So what's what's
that what's that inflection point?
Well, uh it's very hard to get an actual
number right now for tokens, but right
now we are dominating. And uh you know
for me I I'm a student of tech history
like you are. I think about Windows and
Intel. A lot of people here in the 30s
and 40s if you look at the '90s Windows
and Intel was the dominant platform of
software and hardware working together.
So I want us to be the dominant platform
when any token is inferenced all over
the world.
When you think of this this race with
China is this for the United States is
this primarily an economic issue or a
national security issue?
It's both. Um, and they're highly linked
because obviously look, it's obvious to
everybody here the economic impact of AI
and the flywheel that happens when AI
leads to productivity and it makes your
companies and innovation better. But it
also goes into national security because
as you can tell these models and
applications are at the heart of so much
of defense tech and military
applications and they wind up
influencing each other. There's also
national security issue if you have
models from our adversaries running
inside our country or our allies
countries. models which don't share our
value. So for us it's a combination.
Is there any you know we talked the US
China with this very binary. Is there
any other country you see out there and
think yeah they're they're the dark
horse but they they could show up.
Uh I I think look uh the way I see it is
there could be but look I think a lot of
countries want to work with America. Uh
the conversations I've had with multiple
heads of state with multiple ambassadors
is look we want to use your GPUs. We
want to use Nvidia. We want to use AMD.
We want to use other companies. We want
to use your model. So I think a lot of
companies want to work with our comp
with our companies and one of the things
that we have done over the last eight
months is to try and find ways to make
it easier to do so. Uh Daario from
Anthropic was up here and he said he
thought it was nuts that the United
States allows chips, Nvidia chips for
example to be sold into China, albeit
older models of them. You're obviously
part of a White House that is allowing
that at least until today when China
stopped it. What's the ar what's the
counterargument to Daria?
Let me take a couple of minutes on this.
So, so I think there were three mistaken
beliefs that the Biden administration
and a lot of these folks who don't want
us to export chips believe. Number one
is they thought America has a chip
shortage. That's supply constraint.
Second, they believe China can't
manufacture chips. Third, they believe
that China can't do open source models
or models at large. Fourth, they believe
that America is on a path to building
AGI or ASI. AI models can kill us all.
So, we need to retain those abilities.
working backwards. I would say that we
are nowhere on the path of you know
terminator or self-improving AI
regardless of what Eliza Yutoski says.
Uh number two, if you see the news
today, it is very clear that China has
chip capability and in fact they're
trying to stop our American companies
from selling chips to China. So they are
building out their Chinese AI stack.
Third is you know there is no supply
constraint like if you heard like Dr.
Lisa or if you talk to Jensen, you know,
on their earnings or other places, they
will tell you that, you know, we have
all the GPUs that we need for American
companies. And so, uh, and of course,
when it comes to Chinese models, the my
first day on the job, Deep Seek comes
out and we are in a heated race. So all
this leads us now to believe the way to
compete with Huawei and Camrecon, the
way to make sure we don't have a repeat
of what happened with 5G is to make sure
we give chi China these older GPUs in
limited quantities. America has the
latest and greatest in enough quantities
to build these super clusters. But by
giving them these older GPUs limited
quantities, we make sure that Huawei and
Deepseek don't have a flywheel that's in
group. I mean, did Beijing call that
bluff today though by the reports that
they are no longer allowing Nvidia chips
to be sold to their big tech companies?
Well, I think the way they see it is
kind of it sort of affirms what Saxs and
I have been saying, which is like they
have enough chips. They want their stack
to win. Um, there have been news reports
of uh Huawei trying to export GPUs to uh
other countries. So I see this as in a
way of them doing an AI belt and road
initiative and it is on us to make sure
when it's our allies or uh it's the
world over they are using our stuff and
not their stuff. It's interesting. I
mean, if if ch if Beijing kind of agrees
with your point of view on this, which
is why they're doing that as you say,
does that give you kind of concern
because they are indeed going to be keep
plugging more res, you know, Huawei is
going to be able to sell to their
companies. They get more money. They get
to build better chips. In other words,
is is what China did today not allowing
US chips in. Is that actually bad for
the United States in this race? Well, I
think if we can't our companies can't
get developers and applications, if
there is not GitHub repos which are
writing code on American chips, that's
obviously bad for us. But I think, you
know, I want to go back to some of the
people who are opposed to us exporting
GPUs of any kind. I always ask them what
does Huawei want us to do, right? Like
they probably want uh us to not ship
them AMD, not ship them Nvidia. If we if
people are advocating the same policies
that Huawei wants us to do, I probably
have some questions about that. Uh let
me so if if one of the goals of you and
Sax and and the administration is to
build up the as you say the US AI
industry the stack etc. How does it help
US chip makers to have to pay a cut to
the US government when they're exporting
to China?
Well the way we see it is uh look first
uh this there this been kind of a lot of
this fake news about what what has
happened. Number one is what's happened
right? So the Biden uh administration
never actually export control the H20s
or the MI380s from AMD. uh we brought
this under a licensing regime we being
you know the department of uh commerce
where we said we want to know exactly
where the chips are going and in what
quantity
and when you sell them we get a we get
off the top
and I think that you know um I saw uh
the secretary of commerce uh talk about
this the other day look the president
does what he does best which is like
look we are letting you do this you know
let's make sure the
how does that but how does that help the
industry if the indust like in theory
take your Huawei example right the the
reason you don't want Huawei to be able
to sell as much because then they get to
it becomes a virtuous cycle for them
right they get more money to develop. If
Nvidia could get that more money to
develop, that would be good for Nvidia.
That would be good for the US industry.
But they can't because they're giving
some of it to the IRS.
Well, I think the first part of it is
like the fact that they can do this not
just in China, but also we just struck
these Middle East deals uh helps us push
our tech separately. But to your point,
I think the way I see it is the
president got the American people a
great deal.
Got the American people great. All
right. We'll move on. There there's an
there's an EO that I think you were part
of. It's called uh preventing woke.
Let's talk AI rather. Let's talk a
little bit about regulation here in the
in the limited time we have left. Uh
you've said that this isn't that this is
really about making sure there is not
ideology of any sort inside AI models,
but that's not what the EO says. The
EO's title is preventing woke AI. It
talks about DEI, etc. Doesn't talk about
MAGA ideology. It doesn't talk about
libertarian ideology. It's specific. So,
how is that EO not in its own right
imposing an ideology?
It's a great question. By the way, uh I
highly suggest everybody here read the
text of the EO. It's highly riveting.
I'm a bit biased. I wrote a little bit
of it myself. What it says is that first
it has a few examples of the kinds of uh
uh ideology we don't want to see. Black
George Washington. You ask a model for
Nazis, you know, you get Asian people,
black pop.
It say it also says you shouldn't have
anything in there that talks about
discrimination on the basis of race or
sex. So if an AI includes information
that acknowledges that women make less
than men for the same job, that is
somehow woke ideology. Well, what it
says is you need to be truth seeking,
right? There are two
But that would be truth.
Well,
but you but no nothing about
discrimination on the basis of race or
sex.
No, what it says is if you a you need to
be truth seeeking and objective and
second is if you have ideological
sources, just tell us what they are.
Look, we it's very simple. What we want
is you don't put your thumb on the
scale. We don't want either left or
right ideology. We just want any thumbs
on scale. And if you think that you
have, you know, views of the world in
there, that's perfectly fine. But the
model needs to be transparent about what
those views are.
How will I I know the EEO gave 120 days
and we're not close to that yet. How
will you determine whether there is
ideology inside these models?
Well, I think you know OM and a bunch of
agencies are working on the process to
to go do that which actually is another
interesting point here uh because at the
heart of this what do we want? This
these are about taxpayer money right
this is taxpayer money being spent in
these models and we are saying listen
like you free to do whatever you want
but if you want the American taxpayer to
buy your model through the USG through
the DoD A we don't want any ideology or
B if you have biases just tell us what
they are so but there is a process right
now to figure out like you know what the
evaluations and what the uh you know how
the evaluations will happen
uh there's there's a bunch of talk about
AI regulation at the state level uh
California particularly seems to be
moving moving ahead uh there was talk
about putting a moratorium in the big
beautiful bill. It got stripped out.
There was opposition kind of on both
sides of that. I know the White House
kind of wants to get that moratorum back
in some way. In the meantime, if
California passes AI regulation or other
states do, what is your office's
response to that? How do you guys handle
that? What's the contingency plan?
Well, we love to see, you know, when
that winds up happening. Uh our thinking
is very clear. Uh the president came out
and said this at the AI summit maybe a
month and a half ago, saying, "Look, we
don't AI is a national security issue,
right? Like if you're competing with
Deep Seek and Quinn, we don't want every
AI company to build out a huge
compliance department. Trust me, no CEO
here wants to build out a huge
compliance department which has to
figure out, hey, what is California
saying? What is New York saying, right?
And I think there are over like thousand
state laws in the works. Just imagine,
you know, the kind of the drag and uh
the inefficiencies there. So I I think
our view is simple. I think you have
Senator Cruz right after this, you know,
who probably another good person to talk
to. Our view is simple. This is a
national security issue. If you're going
to win against China, we need to think
about this the federal level. Uh but you
know, we got to take it as it comes and
we'll see what happens when one of these
laws pass.
That's interesting. Um two final quick
questions for you here. One, let me when
it comes to US leading in AI. So many
actually actually let me ask it this
way.
Different question. You come from
Silicon Valley. Um Silicon Valley's
always kind of had traditionally a kind
of hard time getting into DC except for
Google during the Obama administration.
Is Sand Hill Road the new K Street?
Wait, what's K Street?
It's where all the lobbyists are. Well,
if it's one,
I generally do not know that.
Okay. I mean, but but I mean, from your
perspective, I mean, does Silicon Let me
ask you this way. Do do you feel does
Silicon Valley have an appropriate
influence in the White House or in DC
right now or too much?
Uh, well, look, I I don't see that at
all. I think, you know, this
administration uh look, somebody like me
had no political aspirations. I I never
badly even made a trip to DC. I was
personally convinced that the country
was going down the wrong path on AI
regulation. Um, what the previous team
was doing was just terrible. and I got
motivated and I think you know what this
president has done has brought together
people from the industry who are just
motivated to come serve. So it's me
David Sax also other people look at Emil
Michael in the DoD uh Joe Joe Gabia
founder of Airbnb uh a billionaire but
he's up here trying to redesign I think
everybody's tax forms and veterans
benefits and whatnot. So I think it's a
testament to the president to pull in
talent.
Final question is about the president
himself. To your knowledge does he use
any AI and if so what? Uh, I actually I
I know I don't know the answer to that,
but I'm sure Baron does. So, but I I you
know what? I should go find out. I don't
know the answer to that. Um, look, I
want to leave you with like one final
thought. There's a great quote from
Steve Jobs I came across the other day.
Uh, it's on my ex-p profofile where Jobs
in like he's kind of he's 38. He's out
of the mix and he's kind of trying to
shave his comeback and he says, "Listen,
I don't really think about technology.
Um, you know, technology is useless.
What I think about is people and I
believe in people." And for me, you
know, a lot of my, you know, the way I
think about AI is like I believe in the
people using AI, be it American workers,
be it everybody here. And that's kind of
the heart of what we're trying to do.
Sure. Thanks so much.
Thank you so much. Good.
[Music]
Please welcome Axio's senior tech policy
reporter, Ashley Gold.
Hi everyone. Thanks again for being at
our Axios AI Summit in DC today. I
wanted to give another shout out in case
you missed it. My colleague Maria Curry
and I will be writing AI plus government
as a takeover to the Friday edition of
the AI Plus newsletter. So make sure you
sign up for that. Get the smartest
reporting on AI and tech policy. Heading
to axios.com for more info. And now to
our next portion of programming.
Washington has been scrambling to keep
pace with AI, and the debates are
heating up. From concerns about national
security, free speech, and regulation,
these conversations are shaping
America's competitive edge. Joining us
next is Senator Ted Cruz of Texas, who
chairs the Senate Commerce Committee.
Senator, welcome to the Axios AI Summit
stage.
[Music]
Thanks for being here with us, Senator
Cruz. We appreciate it. Let's get right
to the point. Um, yesterday you said at
an event that the AI moratorum that you
uh tried to champion through the Senate
is not all dead. Tell us exactly what
that looks like in efforts to revive
that and do you have the support of the
White House in doing so? So, I will say
just listening to the prior speaker, I
think this may be the first time in
history that an executive branch
appointee said he had no idea what K
Street was.
Yeah, you might be right.
That that's truly a remarkable moment.
It's a great thing. So, yes, um I'm
working very closely with the White
House. Uh one of the elements of the
president's AI action plan uh is the
state moratorum.
uh we had an agreement. It was inches
from being adopted in the one big
beautiful bill and at the last minute
the agreement fell apart. So we did not
have the votes at the end of the day.
But but I still think we'll get there
and I'm working closely with the White
House, closely with the administration
on it.
And can you tell us at all what vehicle
that could be in? Will it be in a
mustpass bill for the end of this year?
Is it pushed to next year? I
I think all of those questions are still
under discussion. So we do not have we
do not have a plan we're ready to roll
out yet. Mhm. So tell me what's unique
about AI regulation and that the federal
government should definitively say let's
slow down. Let's not do this. Let's make
sure we have federal standards because
in in other cases you other Republicans
um other Democrats are very much in
favor of states rights and states being
able to regulate how they want. So why
is this different?
Well, let me step back for a minute and
give just a broader overview and then
I'll answer your specific question. But
I think we are at an incredibly
consequential inflection point in US
economic history and and I would hearken
back to 30 years ago uh to the 1990s and
the birth of the internet
and and I'll do something that might
surprise some folks here. I'll praise a
Democrat president, Bill Clinton. Bill
Clinton at at the dawn of the internet
signed into law an executive order that
memorialized a light touch regulatory
approach to the internet. He said we're
going to stay out of it. And by the way,
Congress worked handinhand with him and
so barred taxation on the internet at
the same time. And the internet was a
nent technology.
While the United States was going down
that road, Europe took a fundamentally
different approach. Europe decided to
engage in a heavy-handed prior approval
regulatory approach
and the consequences of that decision
were massive. Here's an amazing stat. In
1993,
the economy of the United States and the
economy of the EU were virtually
identical. Today, the American economy
is more than 50% larger than the EU. And
there are two drivers of that. tech and
the shale revolution. That's it. That
comprises the entirety of that
difference. And you think about there
virtually no major tech companies in
Europe. It killed the tech industry and
virtually every major tech company in
the world is in the United States. We
won that race. I think we are at a
similar fork in the road and if
anything, it is more consequential. AI
is going to transform every aspect of
our life. And by the way, it's coming
whether we like it or not. There are
some folks who say, "Well, I don't like
all the transitions that are coming with
AI." I get that there may be good
aspects and bad aspects, but but I do
not think you will halt the advance of
innovation and technology. And so the
question is which nation wins the race?
China has been explicit. Their objective
is to dominate AI globally by 2030.
They've laid out a plan to have AI
integrated into 90% of their economy,
every aspect of the Chinese economy by
2030.
And whichever nation wins the race for
AI,
the values of that nation
will dominate AI. And so I want America
to win. I want the jobs to be here. I
want the prosperity to be here. I want
the abundance to be here. And I want our
values. I want the values of free
markets and free speech and and
individual liberty rather than the
values of the Chinese Communist Party
and collectivism
and and surveillance and and and
complete government control. So the
consequences of who wins
I think are the single most important
economic decision facing the United
States. Now your specific question on a
state moratorum the answer is real
simple.
We have a national marketplace.
There is no way for AI to to develop
reasonably and for us to win the race to
beat China if we end up with 50
contradictory standards in 50 states and
not just 50 states because cities and
municipalities will do this. And so the
consequence is do you really want Gavin
Newsome and Karen Bass and Comrade
Mandami in New York City setting the
rules for AI and and governing AI across
this country? I think that would be
cataclysmic. And and you mentioned
briefly my being a federalist. I
absolutely am a federalist. If you look
at the constitution though, there's a
reason article 1 section 8 has the
interstate commerce clause precisely
because congress has the authority and I
think in this instance the
responsibility
to ensure that we have interstate
commerce that that can thrive because if
we don't if we let medddling politicians
at every level of government put chains
on the development of AI, we will most
assuredly lose to China because China is
not constraining what's happening there.
So, I want to talk about some of the the
bad aspects of AI you brought up. You're
saying it's not all good. There are
there are hard aspects um and the idea
that we should wait to do major regul
major regulation. Yesterday in the
Senate Judiciary Committee, the father
of Adam Rain, the teenager who committed
suicide after interacting with an open
AI chatbot, he said, "I don't think
states should be waiting to do
regulation. It's it's too dangerous.
It's clearly we're seeing consequences
now. state shouldn't be held back by the
federal government. So, how do you
square your really pro- AI acceleration
stance you just described with what
you've always really cared about, which
is children's online safety? How do you
how do you do that?
Look, I I think you can and you must do
both. I I have been a passionate
advocate of protecting kids online. Um,
listen, I'm the father of two teenage
daughters. It it is hard. It's always
been hard to be a teenager. It is
unbelievably hard to be a teenager right
now with w with with the phones that we
put in their hands that that are portals
to every evil force in the world. I
don't know of a parent who isn't
terrified
about all of the pressures and
influences online that are targeting our
kids. The average teenager spends over
eight hours a day online on their phone.
That is dangerous. And so, you know,
I'll point out I I am the only senator
who has passed legislation directly
restricting AI and done so recently. Uh,
and that is the Take It Down Act. The
Take It Down Act I authored I did it
jointly with with Amy Clolobachar
and and it addressed nonconsential
intimate images. So, so two
circumstances. Number one, real images.
So, you have a romantic partner uh you
have a a two romantic partners that are
intimate together. They take intimate
pictures together. They take videos
together. And then they have a breakup.
Uh, and one or the other decides, "All
right, I'm going to stick it to you, and
I'm going to make these pictures or
these im these videos public." So-called
revenge porn. Nobody has the right to do
that. That is a grotesque violation of
your privacy. And and it is completely
that the victims of that are traumatized
profoundly. There's a second iteration
of it that is directly tied to this
topic which is AI is now enabling deep
fakes and and in fact just today I I saw
uh the young lady who was the the
inspiration for the take it down act. Uh
her name is Ellison Barry and and she is
a high school junior from Texas. When
she was 14 she was a freshman in high
school and she lived up in Alto, Texas
which is in North Texas. She woke up one
morning and a classmate of hers from
school had taken a perfectly innocent
picture of hers from social media had
used an AI to create a deep fake that
appeared to be her naked and then sent
it to all of her classmates. And so she
woke up Monday morning, her phone was
blowing up, all of her classmates are
saying, "I'm looking at naked pictures
of you." And and she understandably was
in tears. She was crushed. I mean,
that's that's hard for anyone to endure,
but especially a teenage girl.
They found who did it, and there were no
consequences for the boy who did it. The
boy continued going to her school. It
was not a crime. Ordinarily, if you send
out naked pictures of a 14-year-old
girl, that's child pornography. You can
be prosecuted for that. But there was a
hole in the law because it was a deep
fake. It didn't meet the definition for
child porn because it was not an actual
picture. It just was
iniccernible. You couldn't tell the
difference between it and an actual
picture.
Well, she is a constituent. And so she
and her mom ended up calling my office
and saying, "Listen, you're my senator.
Can you help me?" And and I want to give
credit to my staff. They elevated this
concern to me. And I I looked at this
and said, "This is horrible. Let's do
something to address this." So, we
drafted the Take It Down Act. It does
two things. Number one, it makes it a
crime. It makes it a felony to post
non-consensual intimate images, either
real pictures or deep fakes made using
AI. But number two, it puts a legal
obligation on tech platforms to take the
content down. And you know, when I
introduced the legislation, I I met
Elliston and her mom, Anna, in my office
for the first time. We were doing a
press conference that day and I asked
her, I said, "Whatever happened to the
pictures?"
And they both said, "It's the most
frustrating thing." They said, "We have
called and emailed Snapchat over and
over and over again." And they don't do
anything. We we just get a complete
stiff arm.
I turned to my team. I said, "I want you
to get the CEO on the phone today.
I want those pictures down today."
Within two hours, they pulled them down.
Now, it should not take a sitting United
States senator making a phone call to
get the pictures down. And now it
doesn't because under the law and and
what we did, and again, I'm going to
credit my staff because it was their
idea, not mine, we borrowed a mechanism
from existing law. So, the Digital
Millennium Copyright Act, been in in law
for a long time, protects copyrighted
material. So if you tweet out a song
from the Lion King, they'll take it down
within hours because you can't send out
copyrighted material and every tech
platform has a notice of take down
office that is devoted to responding to
those complaints because they have a
legal obligation to do so. So we just
put non-consensual intimate images in
the very same category. So that you have
now if you were victimized
and deep fake non-conensual intimate
images have increased more than 3,000%
last year more than 95% of the victims
are women or teenage girls and you now
have a legal right if you were
victimized by this to notify the tech
platform that is me it is an intimate
image and you do not have my consent and
they have a federal statuto
responsibility to take it down
senator we are running out of time, but
I wanted to ask you really quickly. Uh,
since we're talking about legal
protections and and AI, should AI
generated content get section 230
protections? And quick answer because
there we're running out of time.
Look, section 230 was part of that light
touch regulatory approach and I think
section 230 made sense at the dawn of
the internet because you wanted this
nent industry to grow. Now tech
platforms are powerhouses. I have long
advocated for section 230 reform. I
don't support repeal of 230, but I think
we should use section 230 as leverage to
stop online censorship. And and in my
view, big tech censorship has been the
greatest threat to free speech and
democracy that we have seen in modern
times. And so I've long advocated that
that companies should lose their 230
immunity
if they are engaged in censorship, if
they are silent.
there's abusive content out there that
was AI generated or if people want to
sue them over something they read that
you know was inaccurate.
So there's ongoing legis legislation or
litigation on that right now. Um I
suspect the argument will be that under
the plain language of section 230 AI
falls within it. I imagine there will be
litigation on both sides but I think
it's early in determining that. But but
my guess is that current law will
conclude that that that yes it's covered
under the terms of what Congress has
passed. And do you support that?
Um, look, I I again I think avoiding
censorship makes sense, but you know,
you mentioned that the hearing on chat
box. We're going to have to deal with
very real threats and how we respond to
them. I've got a different set of
legislation called COSMPA, the kids off
social media act that I have along with
Brian Shots, Democrat from Hawaii. And
it does several things. Number one, it
prohibits children under 13 from having
social media accounts. Number two, it
prohibits tech companies from using
algorithmic boosting for kids under 17
because so much garbage is pushed to our
kids. And number three, and this is a a
different bill that I have that we
heard, the other bill is called the Eyes
of the Board Act that that says that any
school that is receiving federal funds
has to block social media on campus
because when when kids are in class,
they ought to be looking at the board
and listening to the teacher and not
posting on Instagram. And and so that
what is fascinating about that bill is
virtually all of the sponsors are
senators in their 40s and 50s. And I
will say my colleagues in their 70s and
80s are very puzzled and and don't
they're like, "Well, what's the problem
here?" And every one of us that has kids
at home, as I said, I don't know a
parent that isn't freaked out and
worried, and I think we need to do a lot
more to be protecting kids online.
Thank you, Senator Cruz. That is all the
time we have, but thank you for joining
us today.
Thank you.
Here
[Music]
he is again. Axio's publisher Nicholas
Johnston.
Ah, yes. Here he is again back on the
big stage. Uh good afternoon, Nicholas
Johnson, the publisher of Axio, still at
it. Uh huge thanks to our next partner
into it. Uh this is their second time uh
on stage with me. They were a huge
partner with our AI summit in San
Francisco last year. And so I'm very
excited to continue the conversation
about how real people and small
businesses are using AI with into its
Anup Sher Neasan. Anoop welcome to the
big gilded stage.
[Applause]
How are you?
Good. Great.
We're just talking backstage about what
an interesting room from the 1920s to be
in talking about AI.
Absolutely. I think the juosition of the
old world charm and the new world
technology is just fascinating.
Ah well let's jump into it. So uh from
your vantage point like I last talked
into it a year ago like that's a
lifetime in AI. How has the landscape
for AI and small businesses changed in
the last year?
Uh you're absolutely right. Uh a year is
a lifetime in the world of AI. Uh in
fact a year ago you would remember that
AI was struggling to answer questions
like how many fingers does a human being
have? Um and now see how far we've come.
Um
getting it wrong too. Right.
Indeed. U small businesses have also
been on a similar journey. Um in the
past um small businesses a year ago
would be asking questions like um how do
I use AI and what is it and what are the
applications of it. Now the questions
have evolved. U small businesses are
actively using it. um and implementing
it in their businesses. They're asking
questions like what tools should I
prioritize for AI and what are the ways
by which I could use it responsibly? Um
and also like how will it ever allow me
to conquer my inbox. Uh these are all
questions that small businesses are
asking and we are uh we are helping um
them um adopt it better. um over 90% of
small businesses that we have surveyed
uh use AI in some way or the other and
one of the um the key reasons behind
that is that businesses and um a
government agencies have leaned in to
help small businesses with training and
and resources to help them use AI
better. Um, and this is where I'm really
proud of the work that in it is doing
with the more with AI tour. Um, helping
small businesses get better at it.
Well, dig in a little bit more on that
like on the practical impacts like what
are you doing on the AI tour? What are
you telling small businesses on that
tour? Like how does it work?
Yeah. Uh, so our um general counsel
Kerry Mlean announced uh the more with
AI tour at the Axios AI Summit last
year. Um and it is a nationwide road
show um where we bring in uh small
businesses. We partner with the u the
initiative for a competitive inner city
um and we bring in small business owners
um who can learn about AI and the use of
AI in their day-to-day businesses with
uh free workshops, hands-on tools um and
learn from the experts in terms of how
to use AI in their own um in their own
businesses.
What are the most like so what are the
pieces of that that work? Like are you
seeing like where's the pickup? like
where does a small business person go
like aha this is going to save me hours
or money. So, so one of the things that
they um most of these are tools that
they are either considering or exploring
but in these sessions the the most
engaging sessions the ones where we have
seen a lot of participation is um the
session on responsible use of AI and
this is where we believe that small
businesses want to innovate but they
also want to do it responsibly and that
is a core principle of how intuitit
thinks about AI as well. Uh we believe
that um AI is going to be a significant
accelerant for small businesses. Um over
70% of small businesses believe that AI
will enable them to compete with larger
businesses but they don't have the
resources or the the the tools or
frankly the confidence to apply AI
effectively. And this is where um the
the more with AI tour really helps them
because um the workshop on responsible
AI provides them with guidelines on how
to use AI responsibly. They have
checklists that they can take back with
them um and uh and share with their
colleagues in the small business and see
how they can use it responsibly. And
over 60% of the attendees of the
workshop have stated to us that they now
feel significantly more confident in how
to use AI and how to use it responsibly
in their business.
Yeah. Like so responsibility, trust,
safeguards, like that was the topic of
the last conversation I was up here.
It's a thread through all of it. Like
what is the advice that you give? Like
what are some of those checklists and
specifics that like small business
should keep in their mind before they
deploy these tools?
Yeah. And and some of this is specific
to the tools that they use. How do you
make sure that the data is safe? Um how
do you make sure that there are the
right safeguards around it? What use
cases is AI ready for now versus where
you could see a lot more hallucinations?
Um these are specific guidelines that we
provide to the to the small business and
having the core principles of where you
use AI and where you use humans um is
core to how into it thinks about it as
well. So if you think about um the way
that we leverage AI within our tools, um
AI automates a lot of the the mundane,
the repetitive tasks that you have to do
on a day-to-day basis,
but at the same time um it keeps humans
in control. So I think the core belief
behind it which is automation where it
where it matters and human where it
counts is really the the core behind the
way that
is that where the uptake is happening
like it feels like a year ago there was
like AI curiosity now we're more in AI
implementation where are we on this
curve of
I I think we are in the active
experimentation stage where um small
businesses um that I talked to in the
ICIC events um they have been using AI
in really creative ways. I met someone
who was using AI as their personal
fitness coach. Um so they would ask
questions about hey here's what I ate
today. Uh what how how am I on track and
and I was really impressed by the fact
that um it gave her a great diet plan
and exercise routine and also motivated
her throughout that process. Um there
there are others who are um practically
every email they compose um first goes
through AI and these are common use
cases but they are also enabling
businesses to think about AI in a whole
new way.
Uh agentic AI uh is a topic that kind of
sneaks around a lot about where AI is
going. Is that on your radar?
Absolutely. Uh absolutely. I think that
is one of the biggest innovations that
we've had um in the past year which is
uh how agentic AI has emerged and um it
the the agents unlike traditional AI um
are able to reason are able to also take
action on your behalf and it keeps you
in control but it also allows you to to
offload certain tasks to the agents um
in in in it for in its small business
customers um they are able to go into
QuickBooks and use the the payments
agent um to get paid faster on their
invoices. So um it'll recommend which of
your customers you should go and contact
and send more frequent reminders because
they have been not as regular
and then go and do that
and then go and do that for you. So
that's one of the core things even in
the the the the mid-market space for our
in it enterprise uh suite. It allows the
agents in that cap in that technology to
act as an assistant to your finance team
reconciling transactions and so on.
That seems to be like the real value for
a small business. If I'm a one person
small business, now I've now got another
person. Exactly. Almost.
You you have you have a team. I would
think of um agents more at this point at
least as really higherforming interns.
Um they're really uh enthusiastic. They
are eager to do the job and they
actually like reconciling bank
transactions.
The the perfect kind of intern. Before
we get the hook here, Anoop, I want to
end on one fun AI thing as well with
you. Give me a cool use case you have in
your own life.
So, um uh for me, um I've always been
envious of people who could just pick up
a pencil and sketch a beautiful portrait
of who were sitting sitting in front of
them. And I was never, you know,
artistically blessed and I had no I have
zero talent. Even my stick figures, it's
difficult to compare them to humans. Um,
so what I've been doing now is um I've
been sprinkling AI. I I'm into
photography. I I have a lot of um take a
lot of good pictures of my my friends
and I sprinkle a little bit of AI. I
make um I convert that for their
birthday into a beautiful pencil sketch
or I reimagine them as a superhero or if
they're into, you know, uh art and
history like this uh as a as a beautiful
marble statue right in the middle of a
building like this
and get that feedback like you're
drawing it but with maybe a slight
edure.
Yeah, exactly. It's just that I I get uh
an extra help in and and doing this. And
this is also drives it. This is, you
know, obviously playful and for laughs,
but it also drives home the point that
if you think about AI as something that
allows you to do things that you always
did faster, u maybe you're not seeing
the full potential, but it unlocks new
things that you were never able to do,
things that you thought were was out of
your reach, like being artistic for me,
and that feels magical.
That sounds like an awesome point to end
on. If you come back next year, bring
some pictures.
Absolutely. We'll do. Thank you so much.
Thanks for it. I think we had Ena coming
up next.
Here she is again. Ena Freed.
All right.
Who's ready to move from theory to
practice? So, one of the things I love
about pulling together these demos is
it's a chance to really see what this
technology can do, and I'm very excited
about this uh next one. Regular readers
of the newsletter will know that I've
written about uh this gentleman twice.
First, when I saw his technology at the
TED conference in 2019 and then last
week um when they shared what they've
been up to since. But this company uh
began its work at MIT and it's since
turned into a company. But they're
reading silent speech. So your voice
controls a lot of things today. Now
imagine if you could just mouth the
words. To explain how that works, please
welcome the CEO and founder of Alter
Ego, Arnav Kapoor. Arnov,
[Music]
great to see you. Um, so I think the
best way for people to understand it is
to see it in action. I think we have a
video that shows how this works. Trust
me, it's going to blow your mind.
So, we're not hearing anything. And
that's the point. You're mouthing the
words there and it's being able to
detect it. But it gets even crazier.
So, you're actually slightly mouthing
these, but we can't even see it and yet
it's detecting it. How is this working?
Right. So, I'm not even mouthing the
words. it's detecting really really
subtle engagement of the tongue. Uh so
we wanted to build something that
approaches asmtotically telepathy but
it's near telepathy. I think uh what's
great about human thought is it's
private. You know speech isn't but human
thought is amorphous like you can't uh
you know form a full email in in in
while you're thinking but speech is is
voluitional. So we wanted to bake
valition into the interface and this
enables a a near telepathic interface
with with technology and with other
people.
So some of the other folks out there,
they're implanting stuff in you. They're
actually reading your thoughts. This is
not doing that. You're intending to
speak the words. You're starting it, but
you don't even have to verbalize it or
even mouth the words.
That's true.
What gave you the idea? Where do you
want to take this?
Yeah. I think for if you look back at
the history of computing, we've always
looked at computers as external external
boxes. There's always been this weird
dualism with technology. But I think in
our company, the ethos is about human
extension and augmentation. We want to
design technology that weaves around and
extends the human experience and human
thought. Um, and especially with AI, you
know, I I saw your interview uh with uh
with in Mark Beni off where you were
like taking shots of water while you
were saying the word agent. And that's
how we think about AI today. But if
Oh, it wasn't water.
Okay. All right. Okay. Well, uh, and if
we just flip that paradigm, if we just
think about AI as an extension of the
human mind and if we sort of like
physically interface it, I think that
really brings the best of both worlds.
Well, let's let's talk about AI cuz this
could be a general computing interface
to almost anything. But in a couple of
the demos you shared last week, the
videos, you showed it as a gateway, as
an interface to an AI system. And I
think we have video. I think in this
first one we're seeing language
translation.
Uh so if we can cue that up.
So now you're doing the same thing.
You're thinking what you're going to say
to him. The AI is translating.
So Scott is internally and silently
speaking in English and it's translating
to
Hindi in his voice. So language is no
longer a barrier. So you could have like
a multilingual conversation
and we're seeing the AI piece of this
already. What you're bringing is the the
language interface, the non- language
interface. Um and then in another one
we're seeing it in a multimodal way. So
in this next demo, you know, often times
it's not just what I'm saying or not
saying in your case, but it's what I'm
seeing. So what's going on here?
That's Europa, who represents Europe
shaking hands with America to celebrate
the first transatlantic telegraph cable.
So, for folks who don't know, he
gestured what it was he wanted to ask
about, didn't speak it, and got the
answer back.
Right.
So, this seems like the kind of thing
we'd all want. I imagine there's some
hurdles between where you are today and
sort of all of us having one of these
devices. Talk about what you've
accomplished where you are, but what
still needs to be done?
Yeah. So we announced this big
breakthrough uh a couple of days ago
actually which we call silent sense
which can with really high sensitivity
capture the spectrum of speech. So
mouthing the words which is very easy to
detect but also the subtlest intent to
speak intent is speech and we think
there are a lot of applications across
you know u across technology like
rehabilitating people who can't speak
who don't have a voice like ALS patients
MS patients
and that's probably where it'll start
like again it could be a consumer thing
but usually you start smaller it costs
more you get people who need it the most
so there are people with ALS or MS who
have lost the ability to verbalize words
but can still deliver
some of that intent and through your
technology could be heard.
Yeah, I think that's one of the most
profound challenges of our time. Like
there is virtually no solution for these
patients. Like I've been to hospitals
where the best equipped hospitals you
have caregivers sort of holding an an
alphabet board and going through each
letter one at a time. So it is a huge
problem. Millions of people suffer from
it. And you know for a totally locked in
patient this probably wouldn't work. You
would need an invasive solution. But a
lot of patients do have really sparse
signals in their speech system still and
something like this could really give
them a real-time voice.
And how close is this? Like you know
you've got working prototypes. Where are
we at?
Right. So the stuff that you saw
recently is a pre-production prototype.
We are so this is not the final product.
So we're working on the final product
that's going to be much smaller. It's
going to look much nicer. Uh, I can't
promise you a date yet, but what I can
say with high confidence is that this is
not science fiction anymore. We're
seeing it happening in real time. And I
think this is going to come into the
real world sooner than people realize.
And how big are you all? Cuz I know
you're a company now. You're not part of
MIT, but is this a tiny startup? Do you
have a lot of people? Do you have
corporate funding?
We we Yeah, we we are a full-fledged
company that spun out of MIT. We have
people working across hardware and AI.
Um, and we're recruiting. So,
all right. Well, good to know. I hope
next year we're going to be here in
March. You think on March we could uh
see it in action?
Try it out. We'll have a full telepathic
conversation, you know?
Yeah.
Anyway, thank you so much.
I mean,
week there's some new application and
you know, it's fascinating what the AI
companies like Dario's company. It's
amazing the progress they're making. But
then you also see all the people
building on top that say, "Well, if we
can assume there's an AI engine that can
answer everything, all I have to do is
create a way to speak to it or not speak
to it." And so that's the kind of
innovation we're seeing. That's why I
like bringing these demos. We've got
another one for you in a little bit. Um,
but I want to talk about something
that's near and dear to my heart, which
is the responsibility around this
profound technology. AI's promise is
incredible and it also comes with risks
from bias to accountability. Companies
are under pressure to adopt this
technology really fast. But there's also
a pressure. You can't get it wrong.
These are your customers. And so to have
this conversation, I'm excited to bring
out Navina Singh, the CEO of Credo,
which is a company that's built their
business around deploying AI with trust.
So please welcome Nina Singh.
Yeah.
So, good to see you.
Good to see you as well.
It's a little warmer than the last time
we spoke. We were in Davos the last
time. So, um, you know, we've been
talking all day about the power of AI,
and I think you're a big believer in the
power of AI. Um, but your company
focuses on something that we don't hear
as much about anymore, and I don't know
that it's gotten any less important.
We're just talking about it less, which
is trust. Talk about the role that trust
and governance play, especially in the
corporate world.
Absolutely. You know, it's I think we
all here are big believers in AI and we
spoke about the signaling that AI is
winning is when we get the market share.
The thing is there's a lot to unpack
beneath it. We won't get the market
share if we can't trust this technology.
If consumers can't adopt it, if
enterprises can't scale AI at um you
know speed and scale within their
organizations. So at Crito AI, what we
are focused on is what is trust and how
do you operationalize it? Because words
are easy. How do you actually put this
in practice becomes really complicated?
Exactly. So I think there's a very
scientific method that we've been
deploying for the past 5 years which is
really focus on an arc technology. A is
for alignment. what do you actually need
to measure and it's really conditional
on different use cases and I think
that's where the con contextual
understanding of AI applications becomes
really critical and then once you
understand what you need to measure how
do you actually go and measure it
becomes really critical and we spend a
lot of time thinking about the risks so
that everyone can actually adopt this
with trust and then lastly is compliance
but not just to regulations company
policies uh standards which obviously
are emerging pretty quickly right now.
And who are your customers and what are
they asking for? Where are they? I mean,
I assume they all care about their
reputation. They want to deploy this,
but they want to know that it's not
going to kill their brand. What are who
are your customers and what are they
asking you for?
Yeah. So, currently, Credo AI serves
global 2000s. We serve financial
services, healthcare, pharma, lot of
agencies. And you know what they really
care about right now is adopting AI fast
but with eyes wide open. And a big part
of that is how do I measure that trust
right? So for maybe a CPG and retail
brand they deeply care about
reputational harms. So within that what
are the scientific measures? Bias
becomes one toxicity becomes other
adversarial attacks etc. Whereas if you
are let's say a financial services
company you might deeply care about what
regulatory oversight you have. So are
you meeting the requirements of things
like model risk management. So I would
say there's a lot of ways to define
trust and that's why it becomes really
critical. It's not just about adopting
AI but it's how you adopt AI and do you
actually understand this technology well
enough.
So I I want to broaden out in a second
but looking at credo specifically I'm
curious you know you're you're not a
tiny company but you know this is a
world of tech giants where most of the
oxygen gets consumed either by the open
AI and anthropics of the world or by the
Microsofts and Googles. What is it like
out there when you know Meta is making
these giant offers when Microsoft and
Google can bundle it with other
products? What is it like to be a
smaller company in the AI space?
I think uh a smaller company in this AI
space tackling trust bringing governance
to market very difficult but you know
it's I I don't think uh I would do a
startup if it was an easy problem to
solve. Having said that, just to maybe
unpack that a little bit, I think the
challenges come right now there's a huge
focus on investing in AI innovation, but
we don't see a correlated investment in
safety and governance. The second
challenge is I think governance many a
times is sort of correlated with
regulation and I think that's really
problematic because it's not it's all
about alignment. It's about risk
understanding, measurements, evaluations
and regulation is tiny component of
that. And I think the third thing is we
actually lack AI literacy. Everyone
wants to adopt AI at speed and scale.
But guess what? Our workforces are not
ready for it. They don't understand what
to measure because they're not using AI
as much.
And I want to talk about sort of the
broader conversation actually that I
feel like we are having less of than we
were a year ago around how do we make
these systems safe? How do we mitigate
bias? How do we deal with the potential
for income inequality? Does it bother
you? Like to me, I didn't think we were
moving fast enough on those discussions
a year or two ago. Now, it feels like
we've stopped talking about them or at
least the discussion has gotten pushed
to the sidelines. I felt like no clear
indication of that was the Paris AI
summit. So, we had Bletchley Park and
Seoul where they were really digging
into some of these really thorny
problems. Then you get to Paris and it
was like a trade show. all the companies
were just trying to land European deals.
Do we need to have that conversation and
how do we restart it? How do we get it
back on center stage?
You know, that's such a great question.
I think we are seeing two sides of that.
One is yes, publicly maybe there's not
enough conversation, but we are also
seeing this really flip side in
enterprises who are under a lot of
pressure to adopt a lot of AI very
quickly. But guess what? They've learned
from the past that they can't do that
without understanding and without trust.
So even though there might not be a
public discourse as much as we would
like, we are seeing actually
acceleration on trying to figure out
again
because the businesses themselves want
it.
Exactly. Because the businesses want to
make sure that they are going in with
eyes wide open and and governance
becomes pivotal to making that trust
happen.
And how far do you think that takes us?
Because it feels like in the past tech
companies regulating themselves has been
maybe I would necessary but not
sufficient seems a stretch. Necessary
only sort of happening and not
sufficient. Is business's risk of
harming their own reputation enough to
make the majority of companies do the
right thing?
No, absolutely not. And I think this is
where the AI action plan is a good step,
but it's like just the beginning, right?
So how do you unpack when you say
evaluation and standards framework what
does that mean for a business uh when
you talk about measurements and making
sure open source ecosystem is safe what
does that mean so there's a lot of
unpacking that needs to happen and
unfortunately I I don't see much action
there but more work needs to happen
and one thing that gets held up as sort
of in opposition to trust and safety and
I know this isn't the position you hold
is we got to beat China so therefore
they're not going to worry about it we
can't worry about it we have to
full speed ahead. Does trust and safety
uh have to be at the expense of
competing with China?
Absolutely not. I think it goes hand in
hand and we need to be China. I think
the key thing is but we also need to
trust the systems that we are putting
out in the market. And so if there's a
conversation about the best of breed AI
innovations and we are not talking about
governance, we are not talking about
trust, I think we we should really count
ourselves out then. And where are the
signs of encouragement? What gives you
optimism around the trust and safety
besides the fact that some of your
customers obviously are taking it
seriously enough to buy your services?
Uh first and foremost I think my team uh
we have a very mission aligned team that
deeply cares about this topic but it's
only 50 of us so need more but I think
the second is the AI action plan I think
that was a really good step it's not the
complete step it's a really good step in
thinking about the entire AI supply
chain and where the trust breakdown
might happen and I think we are very
heartened and something we have actively
supported is a strong evaluation and
standards ecosystem really thinking
about open source and risk within that
etc. And I think the third thing is we
need more action. I think we need to see
more investments in startups like ours.
Uh it's less than 1% right now or even
maybe.1%.
Uh so I think we need to see more
investments not only in startups but
also in big enterprises in governance
and safety and risk assessment
and do we have the standards we need to
measure trust and risk? It seems to me
like again I I don't doubt that many of
your customers are taking it seriously
at least to the degree they don't want
to harm their reputation but is there
enough today to know or is it still a
big unknown when you deploy AI can you
do it with relative security ahead of
time that you are doing it in a
trustworthy way or is that something
that can only be measured after the fact
so I think we are in this messy middle
right now uh I think most of the
organizations we work with they know
what does good look like for them but
they don't know whether that good what
good looks like for them works for the
broader ecosystem. So they have their
own set of guard rails and policies and
to your point can we you know hold them
accountable to that that's a tough
problem. But the second thing is we are
seeing early signs of emergence in uh
standards ecosystem through ISO NIST and
others. Um but I think more work needs
to happen. We are not keeping pace with
AI innovation. And I believe for AI
innovation to be successful, for us to
continue winning this race in AI and
building that market share, we need to
absolutely build on trust.
And that's, you know, we've talked a lot
about the corporate side, what companies
are doing out of their own interests,
but obviously companies interests aren't
necessarily the same as the public's
talk. I'm curious your thoughts on how
do we have more of a conversation around
what data isn't there? Quick story. I
was at this amazing exhibit at the San
Francisco Exploratorium on AI and it was
really nuanced. It really dug into the
hard problems. And one of the things I
loved, they had these physical file
cabinets with folders for all the
different types of data that just aren't
in any written down system. So
therefore, they're not in an LLM. We
know these systems are biased. We know
they reflect the voices that are
dominant on the internet. How do we fill
in those gaps? Because my sense is the
AI models aren't going anywhere. The
only opportunity is to make them better.
Yeah, hard problem. Mina again and
call hard problem.
Exactly. Um I think we are seeing three
levels of work that is happening and not
happening. So one is obviously we need
to make sure that the systems within the
companies that are building it needs to
have multistakeholder perspective and
how much we are talking about AI you
know automating and humans not needed
actually humans are needed. um we are
seeing data sets missing not
representing global south as an example
so how do you actually make that happen
I I think the second thing is really
around what matters to the business and
transparently sharing that we've been
talking a lot about transparency uh what
does that mean right so I think we need
a little bit more clarity not just from
the frontier model providers but also
the application developers in terms of
what data sets have they used to build
these systems and that is something
we've been actively advocating for
well we're in DC. It feels like it's I
would be remiss if I only asked you the
hard questions. So, what would you like
to see? You know, you know, very little
has gotten passed on AI from this
Congress. Uh Senator Cruz talked about a
couple of the things that have passed
around deep fakes and um around one's
own likeness, which are very narrow
slices of this, but there hasn't been a
comprehensive bill. If you could have
comprehensive AI regulation, what are
some of the components? What would you
recommend to the folks in the audience?
Yeah, I think that's a really good
question. Uh the three things that we
believe need to happen and I I think
it's a good starting point. One is I
think uh really thinking about the
evaluations and what measurements need
to happen because it is so use case
specific. You cannot have a peanut
butter approach to measuring everything
in AI to make sure it is safe. So
context specific uh measurements I think
absolutely critical and that is
something we are actively working on.
The second is big believer in disclosure
reporting doesn't have to be public but
it has to be between the companies that
are either uh you know uh selling their
AI models or companies that are building
applications. I absolutely believe that
disclosure reporting how you've built
these systems robust system cards what
kind of testing practices have you used
absolutely critical and you can sort of
overlay that um in a in a transparency
report. And then the last thing that I
would love to see is um a little bit
more investment and understanding of how
much our company is actually investing
in trust and safety. Right now it's a
black box. Even the enterprises we work
with, we don't know how much are they
actually willing compared to the AI
innovation. How much are they spending
on AI trust and safety? And I would love
to see that.
Well, thank you so much as always, Nina.
We're going to have to leave it there,
but appreciate it.
Thank you so much.
And hopefully the conversation will
continue.
Absolutely.
[Music]
Put your hands together for our view
from the top moderator, Axios publisher,
Nicholas Johnston.
All right, we are in the home stretch
here. They've put new snacks out in the
back. don't jump up and get them now.
Just know that they're there uh if you
need them. Uh I'm very excited for this
next conversation. I think we'll really
get at the technological heart of AI.
So, a huge thanks to HPE for partnering
with us to help make today's summit
possible. And I'm very excited to
welcome to the stage for a view from the
top conversation, Kirk Bresnicker. He's
the chief architect at HPE and vice
president of HPE Labs. Kirk, welcome to
the AI Summit.
How are you?
Good. Thanks. So uh chief architect
sounds like a cool uh pretty cool job.
So like tell me like at the technologist
like what's the most interesting thing
you're working on right now?
Yeah. So you know we think about HPE
labs uh we think about technical
readiness what's going to be here in 5
10 or 15 years. So we could go out and
and I could bend your ear about the
intersection of quantum computing and AI
how AI might realize for the the 40
years of promise that quantum's given to
us that maybe we'll come together or
we'll talk about our photonix program
trying to understand how we move uh data
whether it's chip to chip or country to
country and keep dividing by 10 the
amount of energy it requires to move
that data. Um or we could talk about
physics inspired neural networks trying
to understand how we could do
declarative and uh deductive reasoning
to complement the creativity of LM. But
I think for us the most interesting
thing right now is integration and scale
which is given these technologies how do
we connect to enterprise? You know HPE
labs isn't an open-ended research. We're
we're we're always linked into the
business potential of our customers and
our partners. And so for us it's trying
to make those connections. How do we
understand fitness of these
technologies?
So a a big piece of it here and this
came up in some of the earlier
conversations is taking it almost from
theory to practice like how do you
deploy this to organizations and how do
you tell them how to use it? Like what
is your role in that?
Yeah. So you know when I was a I was a
very young engineer at HP I was taught a
formula by one of my first managers and
I repeat that to every generation that
comes through our doors and that is
quality is fitness for use as defined by
the end customer and what's important
about that formula is that it demands
dialogue. It requires us to develop
empathy to understand okay given the
technology how will it need to be used.
Now engineers love boundary conditions,
size, weight, power, cost, privacy,
security. What's important with these
technologies is that we have that
dialogue. We have that conversation with
the enterprises, science, scientists,
and engineers who want to use it so that
we can add in those new boundary
conditions. We can educate our team
members about how to be able to
demonstrate that fitness. You know, it's
been I've been in the room where you're
explaining something and we'll bring in
our human rights team or bring in our
privacy team and they'll explain to the
engineering teams something they had not
occurred to them before. And at first
their eyes get really big and then
they'll kind of look down at the table
and you could just hear the gears
turning. I hadn't even considered that.
So the most important thing that we can
do is to educate and to have that
demonstration of fitness and um and
applicability go all the way back not
just through the technology but into the
training of the technologist. I don't
want to stereotype engineers, but I feel
like they're very good at radiating out.
Is it a new trait to teach them to hear
also?
It is it is part of part of the
understanding is that they need to
cultivate and we need to help them
cultivate this broader understanding
because this is you know as everything
you've heard today this is a generally
applicable technology. This is something
where you know we're all fond of saying
AI won't replace the engineer,
scientist, artist or leader but those
who do embrace these technologies will
replace those who don't. So
understanding how we then say you as the
engineering teams you now have a broader
portfolio you need to gain a further
perspective. That's why when we started
our writing our AI ethics principles
back in 2019 it wasn't just the team at
LAPS. We partnered directly with our
privacy uh glo uh privacy team our human
rights team all of the global ethics and
compliance office to bring in their
perspective and use that as the basis
for educating the teams. Uh every
conversation I've had up here included
the words trust and safeguards. Tell me
how that conversation impacts trust and
how you think about it.
Yeah. So for us, you know, something is
it trustworthy? And for me, uh I say,
"Okay, well, let's do those things. Is
it worthy of trust?" And I don't want
that to be a a nebulous term. I actually
want to say what I really want is
confidence. And confidence has a
rigorous definition. Confidence should
be something I can measure. So what
tools do we need to provide our team so
they can measure confidence so you know
because what I want to do is I want to
prove whether I'm proving it to my
regulator my board of directors my team
members my community here's a technology
and here is why it is fit for use and
that's so much about what we've
developed in our principles one half of
them is all actually is the human rights
focus lens the second is that
engineering and together those two teams
have come together and created those
abilities for our teams to be
introspective to understand these new
boundary conditions. They already knew
how to do all the hard engineering. Now
they need to understand how this
intersects with really challenging
societal problems.
Uh you touched on this a little bit on
the at the beginning but it's hard to
have a conversation about AI about like
energy demands and sustainability like
as a technologist at the chief
architect. What is your view of that
debate?
Uh we can't underscore this enough. You
know, right now the average home here in
the US about 1,200 watts continuously
burns. Think about that as like a large
hair dryer left on all day and all
night.
We're talking about gigawatt data
centers now for the AI factories. And
just to put in perspective, that gawatt
is the equivalent of 833,000 average US
homes. So these are going to be
decisions that we're going to make.
These will have import. This will be
material to the outcomes. for us to
understand how do we operate those
systems at superhuman levels efficiency.
How do we provide that radical
transparency not only to the things that
are going into the factory, the water,
the energy, the talent, the
infrastructure, but also what are those
benefits that are coming out and again
when I can demonstrate prove fitness
then I have a much better chance of
convincing people that this is something
this is important this is something we
should support because I can give that
evidence. can answer that question about
what those energy needs will be and how
they'll
and also what is what are we getting
back cuz what I don't want to have
happen is for us to get through all the
end of this and realize oh you know what
this wasn't worth it uh before we lose
you like look into the future a little
bit as a technologist chief architect I
just love that job title chief architect
uh how is this going to start to change
our lives how are we going to start to
see this technology soon
so I I I can think of my own my own job
right and so part of what I love to do
is to understand how people utilize our
technologies. I can look back through,
you know, my 36 years uh at at our
company and why I love the individual
technologies, what I love is what people
can do because I've made that
contribution and I think about now when
I want to understand when I want to
understand the engineer, the science,
the art that is built upon these
technologies, this now allows me to do
that. I can read the equivalent of
hundreds of papers in an afternoon
because I have these AI assistants. I
can be able to digest and understand.
So, it allows me to do my job better.
And we just, you know, I don't think
it's hard to draw that extension. How
much would you do if you could take
those pieces of your job that you don't
really care for, but you know you have
to get done and you could hand them off
and you could have that that
the conversation we had earlier. What if
you had a super smart, super good mood,
infinite intern that can just take all
of those things,
take it all on for you? Well, let's
bring this into the real world in on one
fun thing like I did with everybody up
here. One AI thing like how are you
using it in your life?
Yeah. So, uh I frequently get responses
to my uh tortured works of genius
emails. TLDDR, too long, didn't read. Uh
and so what I use this for often is I
take that last step and say, "Hey, I
just wrote 3 to 5,000 words. uh could
you give me a 300word abstract and maybe
a 50word takeaway and while I can't find
any word of those 3,000 I would want to
take out boy those those are fantastic
event and everyone knows how he loves
smart brevity so I got to endorse uh
that use at AI thanks so much Kirk for
being here and sharing your insights
huge thank you to HPE for making today
possible we've got an AI demo setup
being set up right now and then we'll
have a quick video from the newsroom so
stick
Thanks.
[Music]
Hi, I'm Ashley Gold, senior tech policy
reporter at Axios.
And I'm Maria Cury, tech policy reporter
here at Axios. Together, we write the AI
Plus government newsletter, which is the
Friday takeover of AI Plus. Our
reporting brings you exclusive insights
and scoops from inside the White House,
federal agencies, and Capitol Hill.
We're going to help you understand the
developing debates around AI, trust,
safety, and governance as they unfold
right here in Washington, DC.
Don't miss out. Subscribe to AI Plus by
scanning the QR code.
Thank you for joining us and enjoy the
rest of the AI Plus Summit.
Please give it up for Axio's chief
technology correspondent, Ena Freed.
So, as you can see, they're setting up
for our next demo. Um, but I did want to
share if Nick Johnston were still on
stage, he'd asking me, "So, Eno, what do
you use AI for?" Well, I found a really
clever use this weekend. So, when I come
to DC, a good friend of mine from
college, he has movie night every
Sunday. And so this past weekend, we
were watching Eternal Sunshine of the
Spotless Mind, which for those of you
who haven't seen it, it's a very
complicated movie. And I came in some
ways into the movie, and I didn't want
to be that person that was like, "What
did I miss? What did I miss?" Shh. So
anyway, so I took a picture of the of
the screen and I asked Chad GPT. I said,
"Hey, I met my friends for movie night.
We're watching Eternal Sunshine. I'm
coming in at this point. What should I
already know?" And instantly it caught
me up. And then I found myself sending a
few more emails and so I was like,
"Wait, I didn't catch up. Now I'm at
this point and it told me." So anyway,
if nothing else, you got one fun new use
for chat GPT. Anyway, back to the
serious note again. What I love about
these demos is it really just gives you
for a feeling. I mean, these are a
couple of the thousands of great ideas
that are buil built on top of the AI
systems that we're all talking about.
So, um, yes, uh, we have a very
interesting, uh, device here which we're
going to hear about, and we're going to
be looking to the skies at the
intersection of AI and aerial imagery.
So, I'm going to be joined next by Reema
Matavosian, who's the CEO of Near Space
Labs, and she's showing us how her
company is transforming Earth imaging
with huge implications for business,
security, insurance, and more. So,
please help me welcome Reema.
[Applause]
So good to see you. Now, I will say I
did not realize that wearing a WNBA
jersey was an option. I would definitely
be in here. Uh we share a love of
technology, but also a love of women's
basketball. Rem's hoping to get back in
time for the Liberty game. I fully
intend to be watching the Valkyries at
10 p.m. tonight. But anyway, before we
get to watch any basketball, um so
obviously we've got some sort of a
balloon here. What's going on?
Yeah. Um, first of all, thank you so
much for having me. I'm a huge fan of
your reporting and it's such a treat to
be here. Um, I'm Reema, co-founder and
CEO of Near Space Labs. At Nearpace, we
operate a fleet of robotic vehicles in
the stratosphere, which is twice hard
than airplanes, but much slower than
satellites.
And talk about I mean, I think we all
know planes and now even drones are used
to fly over and collect data and images.
We've got Elon's launching a new
satellite. Then Jeff Lancers a
satellite. There's lots of satellites
there. What does this bring that we
don't have in the others? And I think
maybe we have a video too.
Yeah, I was just looking at people
bringing the device up. Imagine like
needing to bring a James Web telescope
to the stage. That would have been very
hard. So what our technology does is in
a very miniature cost-effective way.
We're able to capture the best data set
that is available globally uh on the
planet today. The way we do it is by
flying our robots uh in the stratosphere
on balloons, helium balloons. They fly
for a couple of hours, map thousands of
square kilometers within a few hours
with high resolution uh sensors. We're
able to do it timely, frequently, and
provide recent uh and fresh data to our
customers.
And so, you know, again, there's other
types of aerial imagery that are being
used for different purposes. And I think
we do have a video so feel free to move
along and show us some of it. But what
um what are some of the industries that
are using it today?
Yeah. So the use of a imagery and earth
imagery in a variety of uh industries is
increasing due to AI. Uh it is very easy
for large organizations, insurance
companies, agriculture ones, etc. to
adopt AI workflows and get use of this
um vast data sources.
So, one of the things you do is kind of
controversial in my neck of the woods in
San Francisco. I think we have a picture
of some of the imagery that you capture
versus the competitors. Well, this shows
right the theoretical level. You're just
getting a much wider view and at a lower
cost I assume because you're not
launching satellites. You get some of
the benefits of both, right?
Yeah. So we're essentially I mean this
these comparison questions are easy and
hard because we are launching a new
brand new category of imaging. So it's
incredibly unique but yes it absolutely
has edges of comparison with other
status quo providers with airplanes for
example uh you know we're able to
capture 10 times more data within an
hour than an airplane. And what one
flight of that little robot over there
captures what 800,000 drones would.
And so this is the one. So in my neck of
the woods, San Francisco, you can barely
get homeowners insurance. So the newest
thing they do is they use imagery like
Remis companies and they say that roof's
new, that roof needs repaired. We're'll
insure the one on the left. We're not
going to insure the one on the right. So
you make it impossible for me to get
home insurance. Is that what I'm
really working hard to for you to get
home insurance? Um, so all of these
headlines that we've seen about people
getting non-renewals were based on
blurry and outdated imagery. I'm sure
people are investing in California
specifically. We know that people are
investing in hardening their homes and
reducing the risk, which means that a
smart insurer what they would try to do
is figure out what are those properties
that they can actually insure because
insurance company as a corporation
doesn't want to lose business. So, if
I'm understanding Remma, what she's
saying is actually they're writing off
San Francisco entirely without that
imagery, which is true, and that it's
this kind of imagery that lets them pick
and choose. Oh, we actually could insure
that one.
Absolutely. It's silly to say that all
of California is uninsurable. I think we
all can agree with that. What insurers
need is recent information that reflects
the risk. And that's what we do. We map
the planet in a dynamic and continuous
manner that allows insurance companies
to understand the risk it that that
exists today
and that's one use is in the
underwriting basically deciding who
qualifies for insurance but I think on
the next slide we have a picture of this
is another time it gets used and this um
you know is when people need data so
talk about some of how your technology
is used in a disaster.
Yeah and thank you for that question. Uh
it's uh we're very proud to be
supporting postc catastrophe work both
from insurance perspective and for
emergency response. This is a high
school in the suburbs of Dallas. Our
technology is able to be over Dallas,
Texas within a few hours, which means
that if there's a hail storm, a tornado,
we're able to map these very vast areas
and detect damage very quickly. What
this does is uh if you have a claim
after a catastrophe, you'll be able to
get a payout within an hour, within a
couple of hours versus weeks and months.
And you know, as climate change
continues to upend how we live uh and
how we built, being able to have
financial resilience, get your insurance
payouts very quickly is going to be very
crucial.
And insurance is one of the things that
allowed you to have a business today,
but that you're not that's not the end
goal. What other types of uses do you
hope to see? Where do you hope to see
that? Uh I was going to say little guy,
but you know, medium-sized guy. Where do
you hope to see it go next?
We we actually call it Swifty. Uh not
after Taylor Swift, after a high
altitude bird called Swift. Okay.
Um so this technology unlocks so many
use cases. Um and you know those include
uh precision agriculture, food security
is going to be very big issue that we uh
that we target in the future especially
with climate change. Uh, w live wildfire
response is another one. We work with
USDA uh to map fires in real time and be
able to give the front of the fire to
firefighters um because today they go in
blind. So essentially we're both saving
lives and also helping suppress fires
very quickly. And I
list goes on
and I understand like sometimes with new
technologies often with new technologies
what you have is you go in with oh we
can do this existing thing better and
then what you end up with is a new
technology that can do things that
weren't possible before. Are there any
kind of wild or crazy ideas that you or
others have had for how you could use
the imagery?
Um I can give you a very funny one.
People want to take selfies from the
stratosphere.
Of course they did.
Yeah.
Is it good enough resolution?
It is not un So that's that's like a
goal is to have it so that from the
stratosphere you can
uh but the live wildfire response I
would say is a is is one where uh our
technology really shines because real
time persistent coverage over vast areas
is not possible with satellite or with
aerial systems. So this I would say this
is one of the biggest uh areas where
we're excited to have impacted.
Well, thank you so much. Give it up for
Swifty and Reema.
Thank you.
Thank you for that.
[Music]
Please welcome Axio's senior tech policy
reporter, Ashley Gold.
Hi everyone, thanks for sticking with us
this afternoon as Washington debates AI.
Congressman Ro Kana has emerged as one
of the most active voices on how to
regulate and nurture innovation
responsibly. He's been at the center of
the Democratic conversation on AI,
raising questions about safety, labor,
and privacy, while also pressing on
America's competition with China. He
joins me now to share his perspective.
Congressman, come on out.
See you.
Great to see you, Congressman. Thank you
so much for joining us today.
Thank you for having me.
Absolutely. Uh very glad that you're
here. Um we had Senator Ted Cruz earlier
who famously led the effort to get state
level AI regulations um banned. Uh
wanted to put it in one of the uh
spending bills. And you have said that
you think states should be able to
regulate AI as they see fit. Why do you
think this is so important?
Well, even Marjorie Taylor Green and
many Republicans thought that was a
awful idea. H how can we just give the
tech companies totally cart blanch to do
whatever they want? We need basic safety
regulations. We need basic regulations
with jobs. We need to have some
protections for workers. Uh and so uh
that idea that we started speaking about
about the the the bill was so
problematic that they had to pull it uh
to get votes. But uh look, I am
optimistic about AI's ability to help
solve disease, to help uh improve
education, to help produce more things.
Uh but just like electricity, just like
any technology, uh it has to be done
with safeguards and regulations and it
has to be done in a way that isn't going
to deeply exacerbate the economic
divides of this country.
So you don't buy into the idea that
we're in this neck-and-neck race with
China and if we overregulate the the
biggest most successful AI companies in
the US, that means that we lose or they
are too caught up in red tape to make
sure America wins. First of all, I I
have a front row seat at this. Uh five
companies in my district are over a
trillion dollars. Uh the uh challenge uh
has not been over regulation. The the
challenge has been actually that we have
no framework, no regulation. Uh no sense
about preparing for the kind of job loss
that we may fa may we may face. Youth
unemployment is at 12%. what what is the
plan in terms of the the jobs for people
who are uh entering after college? Uh we
have no thought about labeling AI
generated content online and social
media. I mean we're just talking about
the radicalization of young people and
no framework in terms of of that. Uh I
have confidence that we can have a
thoughtful regulatory framework and
still lead in innovation. Uh I don't
want to copy the Chinese model. The re
reality is the United States has shown
that it's capable about innovation and
uh and and consumer safety uh and
people's welfare and we should figure
out how we continue to do that.
And with your fellow Democrats on the
Hill, but both in the House and in the
Senate, what is your general sense of
how the Democrats are sort of coalesing
around their own message on AI? you
know, the Democrats are not in power
right now, but I could see them using AI
as a way to sort of differentiate
themselves um in the upcoming midterms.
So, what do you think is a powerful
message from the Democrats about AI?
Well, you're optimistic that it'll be an
election in the midterms. There wasn't a
single AI question asked about 2024. You
know, the only thing they asked me about
is Epstein these days. I don't no one
asked me about jobs and AI. you know,
we've got to as a country start to talk
about the real impact it's going to have
uh on our speech, on jobs, on democracy.
But there's a philosophical difference
between where the Democrats are and
where uh JD Vance and the Republicans
are. JD Vance's view is accelerationist.
Let's just allow the private companies
to do what they want. let them just
continue to develop AI at rapid speed
and not have concern about the
consequences. It is just let the
companies do what they may wherever they
may. Uh my view is that if we continue
that uh Silicon Valley will do fine. My
district will do fine. They're intent on
rewarding my district. They give the tax
breaks to my district. They deregulate
for my district. All of my district is
singing their praises with Trump. And if
if Donald Trump wanted to instead of
having a campaign of helping the
forgotten Americans, help uh the
forgotten Silicon Valley billionaires,
he's he's succeeding. Uh he's doing
great for my district. Uh but the
reality is my district will do fine
regardless of the political leadership.
Five companies over a trillion dollars.
East of the Mississippi, there's one JP
Morgan that that's 800 billion. Not a
single trillion dollar company. I said,
"Jen, I said to Jensen," you're so
successful, you're creating other
trillion dollar companies like Broadcom,
which is supply to Jensen. Uh, and
they're going to make trillions more.
The question isn't, is Silicon Valley
going to do well? Is AI going to
develop? The question is, what about
everybody else? And the Democrat should
say our vision is AI that actually helps
tackle the economic divides where 70% of
Americans don't think the American dream
is alive, where they don't think their
kids are going to have a good paying
job, where they've seen regions hollowed
out. How are we going to use AI in a way
that's actually going to create jobs for
people in communities that don't have
them? What I believe we need a future
workforce administration to hire young
people? I believe we need a thousand
trade schools across this country. I
believe we need AImmies and AI literacy
across this country. Our job as
politicians should be to make sure that
the AI future is one that has the
economic security of every family in
every community. And that's in
fundamentally the difference the age-old
difference between deregulation lazare
let the markets do whatever they want
and uh guiding the markets to care about
the public good and the good of working
and middle class families.
And we're talking about um state level
um legislation um SB53 just passed both
chambers in the California legislature.
Uh do you think that uh Gavin Newsome
will sign it? Now tell me the details of
that state bill. I have not followed all
the state there's so many state
legislative
transparency requirements.
I think I I I think that probably will
if the from what I remember if that's
the Josh Becker bill. Uh but you know I
think labeling AI as AI seems basic. I
mean two basic reforms we can make is
get the bots off social media. I mean
most of the hate the uh terrible content
on social media is bots. Elon Nus when
he took over X he said I'm going to get
rid of the bots. what what what
happened, you know, what happened to you
after that because they're still filled
with bots. Uh and uh make sure that you
have transparency on uh labeling AI as
AI.
And you have talked a lot about how the
Trump administration, they're really
being accelerationist about all of this.
They rolled out the AI action plan,
which basically aims to cut red tape and
make it so these AI companies can go as
fast as they can. One of the aspects of
that is a executive order on ensuring uh
AI isn't woke. So is that to in your
perspective something productive that
the government should be doing? Is there
even really a way
that's like a Saturday night skit? Like
how could AI be woke? I mean who thinks
of these things? Did Grock think of
that? I respond if it wasn't so stupid.
All right. I think I think we can tell
how you feel about that. Uh,
I just What does it mean to have Woke
AI? I understand. Like
I think the companies are trying to
figure it out. They're going to have to
comply with this executive order.
Yeah.
I Here's what I'll do. I'll I'll I'll
I'll take uh comply with Voke AI if we
could have vaccines. How about that? How
about that?
Is that your barter?
That's my barter. Just have some have
the science have some science in the
administration and we'll deal with woke
AI.
Okay. Uh let's let's move on to
copyright. Um there's been some pretty
major court cases um about you know
authors and creators who have had you
know their works uh being trained on by
AI without any sort of compensation. Do
you think that Congress should do
something to create a new copyright
regime so that uh people who hold that
the hold these rights are protected from
AI?
Yes. I mean, I think that you can't just
take people's content, put it in a
machine, spit it out, and not compensate
people for the content. I mean, we
think, okay, wow, they it's AI that's
churning this out, but they're taking
the great writing of uh of authors and
the great works of uh of of artists uh
and journalists and there should be some
compensation for the use of that uh and
then the the aggregation and and and
churning out of that. So absolutely
there needs to be either licensing uh or
some compensation and they can afford
it. I mean I'm not concerned about the
economic profitability of of these
companies. We're producing more wealth
than we ever have in the history of the
world.
Um do you think that companies should be
required uh to give workers a share of
AIdriven profits?
Yes. Again I think if if you're going to
have increased worker productivity then
workers should have a a role in the
share of those profits. If we're going
to have AIdriven factories, which mean
less workers because we need the
productivity advantage. That means the
marginal productivity is higher, that
means that they should have higher
gains. And the challenge in our country
is the economic divide. Uh these are the
types of policies that the Congress
should be working on to say yes that if
you're going to use AI and increase
productivity, how do we make sure
everyone is benefiting from it? Mhm. And
how do you see unions and you know uh
labor forces and labor organizations
having a role in these conversations
about AI in the workplace as we go
forward.
They need to be centered in these
conversations. They need to have a say
so that AI is used to increase
productivity not to eliminate jobs. They
need to be talking about whether we have
excessive automation. What do I mean by
excessive automation? I'll give you two
examples. And this is really not my
work. It's a uh it's it's it's the work
of uh MIT economists uh who have written
about this with much more detail. But
you you call customer service. How many
people have called customer service and
I'm fighting with my phone pressing
zero, pressing star, get me a human
voice. You know, all these improvements
in AI, I still don't deal with the bots
on the phone. And then I get intimidated
every time I'm checking out of like CVS
or Walgreens and you've got all this
self-service stuff and 90 80% of times
it doesn't work. I have to end up
calling the the clerk because it didn't
scan the product or I didn't press the
right amount of bags I wanted or I
didn't do the right payment.
Hey, what happens?
So, look, this is excessive automation.
I mean, and what we need is workers to
be thinking about where where they can
use technology to improve their own
productivity. So, maybe you could have a
customer service person now who has all
the options of your flights and can be
better at customer service, but don't
eliminate the human from that equation.
And this is something that it doesn't
require just management but workers to
be part part of the conversation.
And do you think that corporations are
sort of already uh getting ahead of
themselves like cutting some lower lower
level workers and jobs and uh letting
those jobs be taken over by AI before
they really see how that will work?
Well, I don't think workers have enough
of a voice in uh making a say in how
technology is is is implemented. I don't
believe we have enough safeguards in
terms of the government in terms of
revising our tax code to incentivize
hiring people instead of the
depreciation incentives we have today.
And Duress Moglo at MIT has written
about how we have to revise our tax code
to incentivize hiring people over
machines. Uh and we don't have uh enough
of a sense of apprenticeships and trade
schools or worker participation uh in in
AI. the challenge of AI ultimately for
politicians because the the folks doing
the invention are going to to to invent
it and you know I mean politicians
aren't going to get credit for the
acceleration of AI the challenge for
politicians is make sure AI doesn't
become like globalization but worse
where it uh aggravates the divides in
America aggravates the divides between
uh people who have economic wealth and
those don't between regions that are
succeeding and those that have been left
out that to me it should be our front
and center challenge. So, what's the
first thing Congress can tackle to to do
some of these things that you discussed
to make sure people are more at the
center?
Jobs. We should have a we should have a
jobs vision for AI. In my view, it's
future workforce administration to hire
people out of college if they can't get
hired in the private
as a government agency.
As a government agency, as a government
agency, putting them to work for a few
years so their skills don't uh atrophy.
providing uh tax incentives to get
people hired in in entry- level jobs and
apprenticeships. Making sure that we
have AIM so that people come out
understanding AI skills can use that to
small business or uh for data management
so that they can create economic
vitality in their communities and have
high-paying jobs. Uh we we need a jobs
vision and program in this country uh to
deal with the displacement of AI. And
second, I would say is uh is is
fundamental safety. We should be uh
making sure that AI has thirdparty
audits. We should be making sure it's
clearly labeled. We should be making
sure there's transparency on algorithms.
We should be making sure that there not
the excessive use of bots on these
social media platforms. Do you think
that what's happened lately with some
high-profile cases of uh younger users
of these chat bots um hurting
themselves, committing suicide, do you
think that that will make Congress act
on any of this safety legislation you're
talking about any any sooner?
Well, Congress has been derelictked for
uh a decade. I mean, we haven't done
anything with social media. I mean, I I
love how Josh Holly, and I I'm not
saying this to criticize Josh Holly.
Josh Holly made uh uh Mark Zuckerberg
stand in front of the the the parents to
apologize to them. And someone one of my
constituents said, you know, Zuckerberg
should have said to the Congress to
stand to apologize to those parents. You
know, we're the Congress has been
totally asleep with social media. the uh
Tim Berners Lee and I introduced a
resolution to have uh Tim Berners Lee
the inven the founder of the worldwide
web to have uh the the the the basic
restrictions of people owning their own
data these companies not being able to
to take your data and just sell outrage
the uh ability to have standards for
kids in 2017 and nothing happened. I
believe Governor Cox is is absolutely
right that there needs to be serious
regulations on these social media
companies. We need to be protecting our
kids. We need to be making sure that
there's algorithmic transparency and
then we should be doing that with AI,
but we're we're behind even on social
media.
Um on that note, we'll be watching to
see what what you might do in AI
regulation. And we're out of time, but
thank you so much, Congressman.
Thank you. Appreciate it.
[Music]
Please give it up for Axio's chief
technology correspondent, Ena Freed.
Okay, we're in the home stretch. I
promise there is a reception afterwards.
We can all catch up and catch a drink
and uh eager to hear what you all have
to say. But our next speaker, I'm very
excited, was the most recent addition to
our lineup. Our next speaker is a Navy
combat veteran, a retired NASA
astronaut, and of course now serves in
the United States Senate for Arizona.
His experience navigating complex
challenges from, you know, policy to
national security to space exploration
gives him a wealth of experience as he
talks about AI in the future. And as you
may have read today on Axios, he has a
new policy proposal, an AI plan for
America. So, please welcome Senator Mark
Kelly.
[Applause]
[Music]
[Applause]
Thank you so much.
Hello everybody.
So, you released this AI for America
plan today. I assume all of our readers
have caught up on Axios, but They've
read the whole thing.
They've read the whole plan. The
signature feature is a trust fund that's
paid for by the AI companies. Why do
they owe extra money?
Well, this is more should be thought of
as a partnership between the AI
companies and the companies that benefit
from AI and the public. uh so a private
public partnership where they have a
contribution and you know the reason
that I feel they need to be able to make
this contribution is it is important to
their own success. We cannot put um on
the backs of just the taxpayers uh all
the as an example the infrastructure
investments required to do this. the if
if you just think of this in terms of
energy just in Maricopa County, the
demand which is the big county in
Phoenix, you know, in and around
Phoenix, that area, which is about half
the population of the state of Arizona,
the demand for energy over the next 5
years could perhaps double.
It took APS, which is the big utility,
about 139 years to get to 8,000 megawws
of energy.
They're going to need to double that in
5 years.
And to be clear,
so here's the thing, though. What they
would normally do, a utility would
normally do to build more infrastructure
is they would raise the rates for
homeowners, for small businesses.
Another approach could be that the AI
companies contribute to the AI horizon
fund as we called it to invest in that
infrastructure.
And to be clear, they're they are paying
their electric bills, but they're not
paying when your home rate as a
homeowner goes up because the demand
just
well there there would be no requirement
right now that for homeowners and small
businesses, rates could go up
significantly if the new supply isn't
there. But if you had the money to
invest in the infrastructure and the
supply ahead of time, we could keep
rates lower for homeowners and small
businesses. The other side of this is
obviously workforce.
And you mentioned that there's a number
of ways that this could be paid for. You
don't say we have to do it this way. You
you laid out a couple. What are a couple
of those ways that this could be paid
for?
Well, I mean, we have to figure figure
out that going forward. I mean, what
what pieces of the way that AI companies
generate revenue could be used to
contribute or way ways you can measure
the deployment of AI and use that as um
you know the way you determine what each
company's contribution could be into
trying to make this a success. Hey, I
think that AI is going to be huge for
our economy and we have a competition
here with one of our, you know, another
rather huge country out there, you know,
China that we often compete with in
technology
and we've got some challenges we're
going to face and if we don't have the
right framework in place to lead the
world in AI, they will and we will fall
behind. So, I jumped right into the
elements of the plan, but I want to take
a step back and say why this plan now. I
mean, Congress uh as uh Representative
Connor was saying, Congress hasn't been
passing much big on technology as a
whole. Uh both uh houses of Congress and
the White House are controlled by the
other party. Why is now the right time
for policy? And what what are really the
next steps if it's not passing a law
right now?
Well, I I think a couple years ago was
the right time. um we don't want to wait
another five or 10 years. We need to
have a plan for what this country is
going to look like 10, 20, 30 years in
the future and that starts now. I think
there are great examples where we've had
successes. The Chips and Science Act is
a good example of where
Arizona's benefited quite a bit
and where we've invested in an industry,
we've made the right investments. We're
trying to also invest in the development
of the technology. There's also areas
that Roana mentioned, social media is a
place where I think we've significantly
fallen short
and many of those same harms are going
to come up on steroids with AI
100%. And that's why we should be
putting thinking about this,
collaborating with industry, with
unions, with universities to figure out
what are the guard rails we need to put
into place and what programs do we need
to make this successful. There is a
possibility we could have millions of
people put out of work by artificial
intelligence. Hey, AI companies, they
need customers. You're not going to have
customers if people don't have jobs
because they're not going to have
income. So this having a plan for how do
you retrain people or upskill them or
find other careers for them to go into
that also benefits the AI companies.
And you know I've talked a lot about
there's a number of different risks with
AI. Some of them are if we get AI wrong.
The robots taking over that's if we get
get AI wrong. The
that's getting it really wrong. that's
getting it really wrong. But the jobs
thing comes, even if AI does what it
says, like you're going to have, in
fact, the more it does what it says, the
more of the jobs issue takes center
stage. I mean, Representative Connor, I
think, just proposed, you know, maybe
the government could hire recent college
graduates to make sure they're
continuing getting skills.
I don't know if we want a bigger
government. I I don't think that's the
answer either. I think the answer I
think the answer is is is trying to be
thoughtful about this, getting
collaboration ahead of time, looking out
for workers to make sure workers can
benefit from this. And if we do it
right, like other innovations we've had
where we've increased worker
productivity, we have built a bigger
economy and created more jobs and
provided more opportunity. I think this
could be a huge win for economic growth
in our country.
And have you thought about like what is
the best way because this is a still a
tough cell saying tech companies you're
going to have to contribute more. I
don't imagine you talked about a public
private partnership but it's probably
going to be a required partnership not a
they come willingly to the table.
Well I hope they will come willingly.
What are the steps to take action on it
without control of Congress without uh
without control of Congress? Well, I
mean,
without Democrats being
Well, I I hope to get Republican support
and we're going to start talking to my
Republican colleagues about this.
Are you hoping to introduce legislation
this year on it?
Well, eventually. I mean, we're going to
keep having the discussion before I
release this paper today. We went out to
industry. We got a lot of input. We made
a lot of changes. We're trying to
incorporate the things that make sense.
Uh we did some of that. Some stuff
didn't make sense.
Um, but you know, my feeling here is we,
if you go back a couple years, we spent
a lot of time to bring a lot of people
here to talk to us about AI.
And I felt like not a lot happened.
Uh,
this is when Senator Schumer brought
together and people were really
interested in
they're interested. And then what
happened?
Yeah.
Not not a lot. We have to take the next
step. The White House put out a paper
recently which I thought had a lot of
good stuff in there and a lot of it made
sense to me, but it didn't it didn't
have the it didn't have the next step
like what do we do now?
Well, and it didn't really address the
harms like it addressed how do we create
a great environment for American
technology to flourish, not so much what
do we do with the environmental impact
or the jobs impact.
Exactly.
You mentioned and
I want to get to both the energy and the
unions. You mentioned the unions and we
don't really often hear that. Um why is
it important to have unions at the table
when we're talking about this job
disruption?
Well, because I think unions are always
looking out for workers. Uh and they
often know uh in my view like what do
workers need to be successful? And union
apprenticeships is a good example. That
model could work really well here as
as people are displaced from their
current career and maybe some of them
are mid-career. What do they what do
they do now? Maybe a union
apprenticeship is an option. Maybe they
go from even could go from maybe what's
thought of as a white collar job maybe
into something that's more done more
with their hands or maybe a new career
that is created by AI that we haven't
even thought of yet. But as that becomes
a reality, you know, there could be a a
union role here. There also could be a
community college role. And again, I
think most of the attention today has
been on sort of the economic piece, but
there's also a trust and safety piece.
You call for greater red teaming and
testing. What types of things are
important to you to make sure the
technology is safe?
Well, I I I think the issue with how
this affects children is is one, you
know, clearly at the top of the list.
Social media has not been great for
kids.
Um a lot of children have teenagers have
you know reduced number of real
friendships at this point. You could see
a scenario where an AI
becomes somebody's you know trusted you
know friend instead of a real person. Um
probably not a positive thing. However,
there are probably scenarios where you
have a senior who's rather isolated who
doesn't have because of, you know,
medical conditions or where they live.
Maybe this could be a positive thing.
I mean, that's the really difficult part
with technologies is they tend to be
dual use. They tend to work for some and
not work. And I suspect we're going to
see that with chat bots that some people
are getting a lot of value. They're
really appreciating. They're putting
their medical records in. They're
getting a second opinion. they are
getting a neutral party to bounce an
idea off of. But we're also seeing
people who are, you know, either
struggling with delusions or who are
struggling with depression. And we've
seen for young women, teenagers in our
country, the contemplation of suicide
has gone up dramatically, shockingly.
So, we want to we want to get ahead of
this. And what if you could pick one
element of the plan or one thing that
you think you could get a wide support
like what should we be doing tomorrow
because it's obvious it's what we need
around AI. It's got bipartisan support.
I mean you've picked Congress has picked
a couple. We have the deep fakes uh
non-conensual deep fakes and sort of the
owning your own image and likeness.
Those pieces seem to have
the biggest thing is coming up with a
plan for how you're going to retrain
people for other jobs.
Yeah. And we do not want to find
ourselves in a situation where there are
10 million people that lost their jobs
through AI and they don't have a good
option. That's not good for any of us.
And one other piece of the discussion
has been, and it's only been at the
fringes today, but I've noticed it
coming up more, and I actually thought
this would come about sooner, is the how
should AI answer difficult questions.
Difficult meaning not so much that AI
can't come up with an answer. AI
actually does a pretty good job today,
but there are a lot of people that want
it to answer a certain way. Um, the
White House action plan calls for uh
that all the AI chatbots that are used
by the government be free from political
bias, which if it's stopped there, I
think probably bipartisan support, but
then they define political bias as their
views on gender, right? So, how, you
know, it's tempting to say the
government should step in and regulate
how chatbots answer questions, but Now
you're going down the road of regulating
speech in a way, right? So
there's going to be a lot of AI
companies.
You know, I think some are going to
appeal to some people, some will appear
appeal to others. Uh
so you think it'll be like a little bit
like mass media where people gravitate
to a chatbot.
I think you're going to find that. I
think you're you're seeing it already.
You know, I tend to use chat GPT just
because it's the thing I started with. I
think other people found AI through X
and their or Twitter as I would rather
say Twitter and they use Grock. Um I
think we all have our own preferences
besides the job impact which is huge and
the environmental impact which is huge.
What other things aren't we talking
enough about when it comes to
well it's the infrastructure the energy
usage.
Uh AI could by 2030 consume about 12% of
the country's energy. Um, like I
mentioned, you know, upfront, what we
have to add to the grid is substantial.
In Tucson, Arizona, where I live, uh,
there was a AI company that wanted to
add a data center in Tucson. And when
the community found out how much
electricity and how much water it was
going to use, the city council voted it
down unanimously and they could not get
the permits to start building the data
center in the city of Tucson. I think
they got a plan to be in unincorporated
Puma County as a as an option. But if
there was the infrastructure built ahead
of time and maybe we developed the
technology to be able to cool a data
center using significantly less water.
You know, that's something we probably
can figure out over time if we made the
investment. If we make these
infrastructure investments upfront and
have a fund available maybe for
utilities to do some of the
infrastructure ahead of time so we don't
have to raise rates on people then
you're going to have you you could see
data centers not being shut out of areas
that they feel that they want to build
in. So that helps the AI industry be
able to grow. I was talking to one of
our utilities about the list of
companies that they currently have and
the amount of power they need. It is
shocking and they do not have the
capacity right now. So, the utility is
going to try to figure out how do they
build that capacity.
It's definitely a huge issue. I was at
dinner with um u with u sorry Sam Alman
a couple weeks ago and you know his
needs every time you talk they go up.
So, it's definitely a big issue.
Unfortunately, we're out of time, but
good luck with the plan and look forward
to hearing how those discussions on
Capitol Hill go.
Appreciate it. Thank you.
Thank you very much.
[Applause]
[Music]
Welcoming to the stage Axio's defense
reporter Colin Demerest.
[Music]
What's up everyone? How are y'all doing?
Good to see you here at AI Plus in DC.
I'm Colin Demerest. I write Axios Future
Defense. A quick plug before we get
going here. I have a summit October
22nd, Future Defense. You all should
come. If you need additional details, go
to our website, axios.com.
While you're there, you can also
subscribe to the best newsletter in the
world. Uh, it's free. It can't hurt you.
While you're actually here today,
though, AI is no longer theoretical.
It's here, and it's reshaping defense.
That's from weaponry to intel and the
front lines of the battlefield. Before I
bring out my next guest, a quick video
of what he's up to dayto-day.
Heat. Heat.
[Music]
[Music]
Heat. Heat.
[Music]
[Music]
[Music]
So joining me now is Steve Simone. He's
the CEO of Allen Control Systems and we
will talk about how AI is influencing
the battlefield reality and what that
means for national security and
strategy. Steve,
[Applause]
what's up guy?
Good to see you, man. Thanks for being
here.
Yeah,
thanks for having me.
Of course. So, we have about 11 minutes
here. So, this might feel like a bit of
a
Let's rapid fire. Let's do it.
Let's do it. Rapid fire like the
bullfrog.
Yeah.
How would you assess the state of AI and
autonomy inside the US military as we're
sitting here today?
Um, well, I would I would probably say
that we are a little behind. um you know
all of our weapon systems need to be
enhanced with some form of uh additional
autonomy because if you think about it
taking a step back um in China they are
manufacturing drones at an unprecedented
rate and these things are incredibly
lethal and incredibly cheap and they fly
very fast and they can take out
million-dollar pieces of artillery. They
can crush tanks like never before. And
it's a it's a massive problem. And so we
need an autonomy a stack across
different sorts of products to
neutralize this threat. And I think
right now, as you're seeing on the
battlefield in uh Ukraine, there's
really not a good solution for it yet.
And so, you know, we're one company, but
a lot of us are all trying to figure
this out right now.
When you say behind, are we talking
China? Are we talking Russia? Are we
talking North Korea? Or all three? Well,
I well, Iran, uh, Russia, China, these
countries are making all making drones,
advanced drones. Um, and from a
manufacturing perspective, we're
definitely behind on that. But on a
software side of the house, which again,
America's always led in software. That's
one of our core strengths. We have great
universities. Um, but it's a matter of
actually getting them procured. So, like
there's a lot of great technologies
needing to be unlocked. Uh, and you
know, you're seeing the administration
right now make a lot of big changes. Um,
you see the new task force for
countering drones. A lot of big changes
right now to help actually get this
stuff onto the battlefield and into war
fighters hands.
Let's go that direction of that task
force. What letter grade would you give
the US military for its drone defenses
right now? And what does the task force
need to be successful?
I give right now I give us a D. Like
we're we're not we're barely pass I
guess that's is that passing D?
I have only ever gotten that. So, um,
no, we're, yeah, we we don't actually,
uh, we're not, we're not doing well like
currently. Um, but we have a path to do
a lot better. Um, and so you're seeing
like, you know, for the last 8 years or
so, our country's invested in electronic
warfare. So, that's basically like
trying to zap the drones out of the sky.
Um, or, you know, jam the communication,
jam the GPS of the drone. Um, so
electronic warfare is like a soft kill
measure. The problem is, if you look at
what's happening in Ukraine, Russia has
a new version of the Iranian shahed. you
can't jam that anymore. Like it's not
it's really much harder to jam these
now. And we've invested in, you know,
some of the wrong things. Um and so
you're starting to see a lot of the
industry trying to change that and catch
back up because u the soft kill measures
aren't really working aren't going to
work that well for the next couple
years.
And with that task force uh that
Secretary Haggath announced, are you in
talks with them? Have you consulted with
them? And how would you like to help
them achieve their their goals? Yeah,
we're we're very excited at Allen
Control Systems about the task force. Um
yeah, we we're in talks with them. They
are they seem to have a lot of um you
know energy right now. They have a they
have budget and they have authority.
They're the task force has a lot of
teeth. So we think it's going to drive a
lot of change and we're really happy
with what the administration has done.
Do you think the army leading that task
force was the right decision?
Definitely. Yeah. If you think about it,
like we we need to make uh tanks great
again. And uh the army has a lot of
tanks and you know, one of the ways to
make them great again is to be able to
let them counter drones cuz right now
with the tanks, you know, you're going
to hit them with a drone. So, we need
some new solutions and the army heading
it up actually makes a ton of sense.
And let's stay on counter drone. What do
you think the US needs to prevent a
Tower 22 attack overseas again or a
Operation Spiders Web here domestically?
take the overseas one first, maybe a
little easier. Um, because obviously
spiders web is a very distributed
attack, which would which would mean we
need a lot of stuff in a lot of
different places. Um, on a base overseas
like tower 22, we need a layered defense
system. So, of course, we still need to
have the electronic warfare cuz, you
know, hopefully maybe some of these
drones are the older style that you can
still jam. So layer defense with that
plus kinetic solution like Bullfrog um
which is like a our AI machine gun um to
shoot drones and then you know maybe
another sort of um you know potentially
other sort of soft kill solutions
layered in with that and then better
tracking and like better knowledge of
the full battle space the full airspace
because these things can come from
anywhere and so you you a lot of times
our systems only look like one direction
so we need like better like full bubble
search of the sky. How are you guys at
ACS thinking through networking and kind
of the tasking and queuing because it
said in the video you guys are fad C2
lattis ATAC enabled.
Yeah, I mean the the way it works as a
government contractor is you know we
have a product um like our like Bullfrog
and depending on which branch of service
you're working with could be the
Marines, Army, Navy, they all use
different uh what's called command and
control software. One could come from
one company like North of Grumman. One
could come from and one could you know
there's the Marines have a one that
comes from not one of those primes. So
you're the job is to make sure to
integrate with whichever platform you're
going on. And so there are many command
and control softwares in the military
which means you have to hire a lot of
engineers.
Basically
with Bullfrog there's a bunch of
variants right uh including M240 which
is a reference to the very widely
available machine gun out there. Shoots
762 NATO. Yeah.
Why did you go that route uh with such a
widely available ammunition and weapon?
It's all about the cost. So the the M240
is a widely available gun, the standard
NATO ammunition 762 round. We wanted to
be able to use the cheapest ammo. If we
make a robotic solution that's so
precise and so um fast and quick moving,
you can use like really cheap bullets.
That's like the innovation we've
unlocked. Um, and the drones again,
ranging from a,000 to $10,000 for these
small FPV drones. Interceptor missiles
just really don't make any sense. Um,
and right now what we're doing, we we're
invested in a lot of electronic warfare
like I mentioned. And then the other
thing we invest in as a military is
interceptors. The the US military, uh,
we make some of the best interceptors in
the world. But, you know, you can only
they're more expensive than the drone.
And so that's just not going to be
long-term sustainable.
To that point, right? You look at the
Red Sea, you're seeing standard missiles
taking down multi-million dollar
standard missiles taking down $10,000,
$100,000 shieds. What lessons have you
pulled from that conflict? The Navy
expended I think more than a billion
dollars in those exchanges and how are
you applying that to Yol's work?
I mean, the main lesson is that what's
what's happened what's changed is that
any country or clandestine group can now
wage an effective war. It used to be
expensive for a country to wage war, but
now with the advent with the, you know,
the the rise of the drone, it's just
it's very easy to be disruptive. So
that's what that's the main thing from a
strategy perspective we're learning,
which obviously isn't fun for our
country. Um, and then from a just an
operational standpoint, you know, we're
not going to let these Houthy drones hit
our warships. So we're going to we'll
take them out with what we have
currently. Um, and again, but we need to
get our manufacturing built up to be
able to like buy those expensive
artillery shells or, you know,
interceptors, use those, but in the
meantime, also invest in solutions like
ours, which is going to be like a a much
cheaper way to do this long term.
So, I've always seen Bullfrog in the
back of a truck. It was at it was in in
the back of a truck at Reindustrializ in
Detroit.
Do you foresee naval integration to the
point about warships? Um, where else are
you guys looking to put the turret? So
every mounted gun on every vehicle for
pretty much every military that's our
NATO and our ally other close allies and
all the US you know army navy marine
corps any mounted gun on any vehicle
needs to be replaced with an AI version
of that of itself in the next 5 to 10
years um so that's a lot of uh vehicles
as you can imagine because they all need
to be able to shoot drones because every
vehicle is now in jeopardy like you
can't go from point A to point B on the
battlefield without potentially getting
ambushed by FPVs laying in a cornfield.
They've strung up those massive overhead
nets.
Yeah. I mean, yeah, they Yeah, the nets,
you know, that's a good that's kind of a
solution, I guess. But, you know, what
they do against those is they just send
three drones. First one blows up the net
and then the next two come in and finish
off the rest. So,
stuff
with Russia, Ukraine, um particularly
Russia recently, we saw those air
incursions from Russian drones into
Poland, um into Romania, I believe, but
the the Poland one has been widely
reported scrambled F-35s. Talk about
cost curve.
Yeah.
What are your takeaways from that? Um,
can NATO properly protect its airspace?
And if not, how can it get there?
I mean, you're seeing Estonia, Poland,
Romania. Yeah, obviously Ukraine. These
are the countries are all gearing up
because they know that Russia will not
stop. They're they're coming and it's
happening. In Estonia, they're digging
trenches right now. Like, so they're
these countries are smart. They're
buying stuff. I think Poland's like
buying tons of tanks right now to
prevent a land invasion. Um they're
they're you know scared and they're they
know what's happening and so yeah I
think I think NATO will step up. I think
our administration expects them to step
up. You're seeing that um and I think
they are responding and doing it
with the 5% spending is what
Yeah. Yeah. Yeah.
Do you think the drone incursion was an
accident as some have said?
Uh I think it was like a warning shot
across the bow like get ready. Do you
expect more of that to come and are you
are you guys getting ready for that?
Well, I'm trying to, you know, get the
product out to the over there so that we
can you help out of course to Ukraine.
Yeah, Ukraine and then all the
surrounding countries as well.
And what do you attribute this explosion
of physical AI to smart machinery,
robotics, drones especially that are
jam-proof so to speak.
Yeah, robotics is an incredible like
growth industry. I mean I as a kid you
know electrical engineer I was making
robots my co- business partner Luke
Allen you know he's been making robots
since he was a kid and now you're seeing
that these things we are making as
children are like becoming massive
businesses and investors are pouring
tons of money into this not just in
defense but you know see the humanoid
robots seeing all kinds of this stuff.
It's it's really like incredible to see
and it's because the robotics industry
like now like the servo motors, the
gears, the joints, like the software,
it's all becoming it's all at this like
really advanced now that the robots can
do are a lot more capable than when we
were kids.
At any point did you argue for it to be
called Steve Control Systems? Yeah.
Allen systems. Well, my last name is
Simone and that's like an Italian name
and Simone Control Systems doesn't sound
very as good as like I don't I don't
trust that control.
It's got to be Allen Control Systems.
It's much more American name. Yeah.
What do you say to kind of the defense
tech haters? A new Gallup poll uh found
48% of America Americans, excuse me,
oppose the development of AI enabled
weaponry.
Well, I'm not seeing that with the kids
graduating. I mean, pretty much every
top school that does robotics wants to
be a part of what we're doing. So, I'm
not seeing it there. But, I mean, as a
on the national poll, I believe the
polling numbers, um, I think that is
maybe a little misguided. like we're
we're doing this to defend the country
to project power so that you know the
our adversaries don't continue to
encroach upon our territory.
We got a few seconds left here and I
would be remiss if I didn't ask this.
Last September I interviewed you. You
were one of the first interviews for
future of defense and at the time you
said you were Palmer maxing.
What does that mean to those who aren't
hip enough and are you still doing it?
Um no I've moved to Alex Karp maxing
now. Try to get the hair. It's not wild
enough, but they that's cuz they did it
back there. They But I wanted them to
go.
Did you ask for the Alex Karp in the
green?
Yeah, they didn't do it for me though.
But no, no, I think like look, we look
up to these they they start like Ando,
pound two, these companies kind of
helped pave the way um for companies
like ours. They've brought a lot of
attention and investors here and we
thank them a lot.
Yeah, Steve, we're going to have to
leave it there. And to y'all in the
audience, stick around for one last
panel.
All right.
[Applause]
[Music]
[Applause]
[Music]
Give it up for Axio's tech policy
reporter, Maria Cury.
All right, how are we all doing?
Listen, I know this is the last segment
before we can all break out for the
reception. I promise you it'll be worth
it. Our final conversation is going to
be about widening the lens a bit.
Governments right now are wrestling with
how AI is going to reshape the economy,
geopolitics, and of course, national
security. The timing for this
conversation really couldn't be better
as we just had the fourth delay on a Tik
Tok ban. Joining me for our closing
segment is White House economic adviser
Jacob Hellberg. Jacob, welcome to the
stage.
Hello.
Good to see you.
Thanks for joining us.
Okay, so Jacob, let's start with
manufacturing. You are of the belief
that the United States can once again be
a production-based manufacturing-led
economy and erase the advantage of
lowcost labor overseas. Why do you
believe that?
Absolutely. So, first of all, it's great
to be here and um we're having this
conversation at such a timely point in
time. For most of the 21st century, in
the last 25 years, the global economy
has been driven by a core set of
assumptions that we're seeing the Trump
economic revolution and artificial
intelligence slowly dismantling. And
what I mean by that is three of those
assumptions are the following. that the
US economy is primarily a
consumption-driven
uh services-based economy that grows
between 1 and 3% per year. Um the other
assumption is that AI was going to lead
to mass unemployment and jobs
displacement.
And um the other assumption was this
notion that China was on an unstoppable
rise to eventually overtake the United
States primarily because of uh
structural advantages in its population
and demographics. Um part of what we're
seeing is uh leading indicators in a
massive re-industrialization in the
United States. What are those leading
indicators? We're seeing over a trillion
dollars worth of he of investments in
heavy industrial sectors in the United
States. Um this year for the first time
investment in AI infrastructure is
actually outpacing consumer spending. Um
AI infrastructure investments are
actually contributing over a third to
towards economic growth and GDP. and
economic growth in GDP is is hitting
3.3% this year and uh according to
Secretary Lutnik could potentially hit
4% next year. So we're actually seeing
these investments translate to
potentially a shift in the growth band
of the country from 1 to 3% to
potentially four and 5% which would
really be a step change in productivity.
The last point that I would add is um if
we think about why you said that um that
you know one of the the core thesises is
that AI could potentially erase um the
labor advantage that developing
countries have and I actually think
that's completely true and that's a
fundamental concept. The reason is that
AI increases productivity. So if we look
back in history during the first
industrial revolution, Britain the
industrial output per capita of Britain
during the first industrial revolution
in 1913 was 65 times higher than
industrial output per capita in China.
And the reason is simple. It was all
about tech. Britain had superior tech.
It was able to completely outproduce
China at the time. But Jacob, how
realistically is the United States going
to overcome high infrastructure costs,
high labor costs, talent gaps, and
disruptive tariffs?
You're already seeing that, you know, I
think the answer is actually being
played out in real time. I mean, over a
trillion dollars a year in
infrastructure investments is showing
that the productivity gains far outweigh
the costs of these investments. Um,
we're seeing demand for energy. demand
for energy and electricity production fl
was flat in this country uh basically
between last year and 2008 and for the
first time in a generation it's actually
moving up which is a good sign because
it means that our economy is becoming
more uh energy dense because we're now
seeing an expansion in industrial
activity and because these AI factories
need a lot of energy. So it's, you know,
people could theorize different reasons
for why this is taking place, but it's
hard to deny the fact that it is taking
place.
I want to get your thoughts on this
since you are advising the White House
on economic policy. The Trump
administration has just decided to take
a direct stake in Intel. Do you view
this as the start of a permanent US
industrial strategy or is this just a
one-off fix for a company that was
struggling? Look, um the the US
government was uh obviously, you know,
took a pretty unique step in providing
very large um financial advancements to
uh a number of companies in the last
administration. Um I think of the the
Trump approach to boosting industrial
activity here uh in through four prongs.
Taxes, trade, deregulation, and energy.
Those four prongs are fundamentally what
are what's driving industrial activity
in the US. Um deregulation means
dramatically compressing the windows for
permitting and NEPA reform which was
included in the one big beautiful bill.
Taxes is a huge driver. So the one big
beautiful bill actually has full
expensing for capital investments,
intensive capital investments um which
is actually changing the economics of
investment since you brought up costs
energy. The president reopened Anoir. Um
he is uh he set very ambitious targets
for nuclear energy production which is
direly needed in this country because we
need to dramatically expand our energy
supply. So, and trade for the first time
in over a generation, we're actually
starting to rebalance our trading
relationships with partners. And I think
it's quite unprecedented that we've had
an an administration that's uh basically
concluded over a dozen trade deals with
our major trading partners in less than
a year. So, usually people spend almost
four years to get a single trade deal
done and we're, you know, up to almost
12 now. What about this idea of imposing
tariffs on semiconductors for companies
that are not relocating back to the US?
How does that work practically? Is that
a good idea in your view?
So, um I I'm not going to comment on the
specific breakdown of the application of
tariffs, but what I will say is because
I it sounds like you're referring to
tariffs applied to semiconductors coming
from China from Taiwan. Um from memory,
negotiations with Taiwan are still
ongoing. So, I'm not going to prejudge
what the outcome of those negotiations
will be, but what I will say is um
fundamentally
the the the administration is basically
building the rails for a new trading
system. We had the United States was
running a $1 trillion trading deficit
with our top 12 trading partners every
single year. that is not a sustainable
place for us to be and it's actually bad
for our fiscal deficit and our long-term
growth. And so tackling that issue I
think was fundament was an economic
security issue and that's exactly what
they're doing. Um and and we are seeing
real benefits. I mean the US is on
course to bring in $300 billion this
year alone to the Treasury to pay down
the deficit. And the CBO estimated that
we could bring in up to $4 trillion over
10 years, which completely changes the
fiscal outlook for this country.
Another unprecedented move by the Trump
administration has been taking a cut of
Nvidia chip sales to China. What message
does that send given that China is
viewed as the largest national security
threat to both China and US companies?
Well, and I'm sure you saw the Chinese
government basically um u opened uh an
investigation to probe whether or not
they wanted to block those imports. Now,
um, look, there is a really big debate
going on on what the right balance is,
um, between national security concerns,
uh, that aim at protecting our most
valuable intellectual property and the
tension of competing for market share
internationally.
Where do you land on that debate? It's,
you know, it's it's a really uh there
there's classified information that I
haven't yet been privy to being, you
know, as I await a floor vote for my
incoming rule. But, um, fundamentally,
here's what the tension is.
um the China, you know, there are some
people in the camp that basically say
that uh China's production capacity is
is narrowing the gap and and could
potentially catch up to us and
eventually fill the void in global
demand. And those, you know, who
basically argue that they're actually
quite far behind, it's hard to really
know exactly because China is a very
opaque system. Um there there is
classified information somewhere in the
US government um uh which again I
haven't uh closely studied but at the
end of the day there's a really big
metal level question as to um um whether
we assume that we can continue leading
the world technologically if we don't
also dominate in market share. you know,
there is a value in market share and so,
you know, striking that balance is is
incredibly important because we need to
protect our technological lead while
also making sure that our trusted
partners have access to the American
stack.
Um, Jacob, you advise the president on
Tik Tok and I would love to know just
did you see it playing out this way?
Well, I did not advise the president on
Tik Tok. Uh I was involved in
deliberations in Congress and
conversations in Congress. Um so um
obviously we wouldn't be talking about
this issue had it not been for President
Trump's efforts in his first term. Um at
the end of the day, my view is no
president has done more to align our
economic policy with our national
security imperatives than President
Trump. the our biggest economic security
risk is our industrial over reliance
with China. Ultimately, right now, the
administration has pursued an aggressive
diplomacy with the Chinese government to
have a holistic conversation about what
the shape of a new trading regime is
with China, which actually includes the
tech component of it, um, including Tik
Tok. And so it would be premature for me
to prejudge the outcome of those
negotiations, but I think it's fair to
say that uh we have an incredibly strong
champion in the president.
If there is a deal where China continues
to control the algorithm, will that
satisfy you?
Uh I'm I I'm not going to prejudge the
outcome. I think that's a hypothetical
and you know, I'm just not going to
prejudge the outcome of those
discussions.
Okay. So moving on to the workforce, you
have flagged that we're at risk of
falling behind on AI, but what policies
should the government be responsible for
to ensure that displaced workers do have
a path forward?
Look, the our number one opportunity
with AI is productivity. And here's why.
There is a macroeconomic theory called
Jevans paradox which basically says that
efficiency drives demand. when the the
use of a commodity or resource becomes
more efficient, demand for that
commodity and resource goes up, not
down. So if labor becomes much much more
efficient, demand for labor will go up.
Um uh an interesting fact is that in
2018, 60% of the jobs in 2018 didn't
exist at all in 1940. And and so if you
went back in 1940 and told bookkeepers
and receptionists that in in the 80s
you'd have the personal computer
revolution, I'm sure a lot of them would
actually say that, you know, they a lot
of jobs would be lost and that the
computer was going to lead to mass uh
job losses. What we've actually seen
since the computer revolution since the
between 1980 and 2015 is the destruction
of 3.5 million jobs versus the creation
of over 19 million jobs
but in that transition people are
displaced right does the government have
a role to play there
did the I mean you tell me what role did
the government play during the personal
computer revolution I think the notion
that the government necessarily has to u
hold the hands of every single person
getting displaced actually you know
underestimates the resourcefulness of
people. If you think about the computer
revolution
um you had the software revolution that
came out of that. You had enormous
wealth. I mean our biggest companies as
a country are basically mostly software
companies. Um, and so I think that, you
know, we the the top- down approach
where we assume that the government has
to have the answer to everything
actually underestimates the incredible
uh adaptability and resourcefulness of
the private sector. Jacob Hellbrook,
thank you so much. And before we all
break, I just have a few quick
announcements. Bear with me here. We
have a few upcoming events that you
won't want to miss. Next week in New
York, we will have an Axio's house for
ANGA. Later this month or next month,
we're going to have the future of
defense summit with my colleague Colin
Demerest. In November, you won't want to
miss BFD in New York. And then the very
last AI summit of the year is going to
be in San Francisco in December. And as
you've heard already today, this summit
next year is going to be moved up to
March. So, please mark your calendars.
And beyond that, I just want to say a
huge thank you for our events team for
making this happen, our wonderful
speakers, the audience, and thank you so
much. See you at the reception.
Heat.
[Music]
Heat.
[Music]
Heat. Heat. N.
[Music]
Heat. Hey, Heat.
[Music]
