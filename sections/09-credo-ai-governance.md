---
layout: default
---
# 信任的實踐：Credo AI 談企業如何負責任地部署 AI

**日期:** 2025年9月24日
**講者:** Navina Singh (Credo AI 執行長)
**主持人:** Ena Freed (Axios 首席科技記者)

---

## 前言

AI 的承諾令人難以置信，但隨之而來的風險——從偏見到問責性——同樣不容忽視。企業面臨著快速採用這項技術的巨大壓力，但同時也承受著「不能出錯」的壓力。如何在這兩者之間找到平衡？Axios 首席科技記者 Ena Freed 邀請了 Credo AI 的執行長 Navina Singh，深入探討了企業如何才能在部署 AI 的同時，建立並維持信任。

Credo AI 是一家專門圍繞「可信賴 AI」建立其業務的公司。Navina Singh 在對話中分享了她對 AI 治理、風險評估和標準建立的見解，並強調了為什麼在與中國的競爭中，安全和治理非但不是絆腳石，反而是致勝的關鍵。

---

## 背景資訊

*   **Credo AI:** 一家專注於 AI 治理和監督的平台公司。它提供軟體解決方案，幫助企業評估、管理和監控其 AI 系統的風險，確保這些系統符合公平性、透明度、安全性和合規性等道德標準。
*   **Navina Singh:** Credo AI 的執行長 (CEO)。她在將 AI 治理原則轉化為企業可操作實踐方面，是業界的領導者之一。

---

## 對談內容

**Ena Freed:** ...一週內總有新的應用出現，你知道，像 Dario 的公司這樣的 AI 公司取得的進展令人驚嘆。但你也看到所有在頂層開發的人說：「好吧，如果我們可以假設有一個能回答所有問題的 AI 引擎，我所要做的就是創造一種與之對話或不對話的方式。」這就是我們看到的創新。這就是我喜歡帶來這些展示的原因。我們稍後還有一個。

但我想談談一個與我息息相關的話題，那就是圍繞這項深刻技術的責任。AI 的承諾令人難以置信，但它也伴隨著風險，從偏見到問責。公司面臨著快速採用這項技術的壓力。但同時也有一種壓力：你不能出錯。這些是你的客戶。為了進行這次對話，我很高興能請到 Credo 的執行長 Navina Singh，這家公司圍繞著以信任的方式部署 AI 建立了自己的業務。所以請歡迎 Navina Singh。

**Navina Singh:** 很高興見到你。

**Ena Freed:** 也很高興見到你。這裡比我們上次說話時暖和一點。我們上次是在達沃斯。所以，我們整天都在談論 AI 的力量，我想你也是 AI 力量的忠實信徒。但你的公司專注於一個我們現在不那麼常聽到的東西，我也不認為它的重要性有絲毫減弱。我們只是談論得少了，那就是「信任」。談談信任和治理所扮演的角色，特別是在企業界。

**Navina Singh:** 當然。你知道，我想我們這裡所有人都對 AI 深信不疑，我們談到 AI 獲勝的信號是當我們獲得市場份額時。問題是，這底下有很多需要解開的東西。如果我們不能信任這項技術，我們就無法獲得市場份額。如果消費者不能採用它，如果企業不能在組織內以速度和規模擴展 AI。

所以在 Credo AI，我們專注於「什麼是信任」以及「你如何將其操作化？」因為說話很容易。你如何真正將其付諸實踐，變得非常複雜。所以我認為我們過去五年一直在部署一個非常科學的方法，那就是真正專注於 ARC 技術。A 代表對齊 (Alignment)。你實際上需要測量什麼？這真的取決於不同的使用案例，我認為這就是 AI 應用的情境理解變得非常關鍵的地方。然後一旦你理解了你需要測量什麼，你如何實際去測量它，就變得非常關鍵。我們花了很多時間思考風險，這樣每個人才能真正地信任地採用它。最後是合規性 (Compliance)，但不僅僅是法規，還有公司政策、標準，這些顯然現在正在迅速出現。

**Ena Freed:** 你的客戶是誰？他們在要求什麼？他們在哪裡？我的意思是，我假設他們都關心自己的聲譽。他們想部署這個，但他們想知道這不會毀掉他們的品牌。你的客戶是誰？他們在向你要求什麼？

**Navina Singh:** 是的。目前，Credo AI 服務於全球 2000 強企業。我們服務金融服務、醫療保健、製藥，以及很多機構。你知道他們現在真正關心的是快速採用 AI，但要睜大眼睛。其中很大一部分是「我如何衡量那份信任？」對吧？所以對於一個消費品和零售品牌來說，他們非常關心聲譽損害。所以在這之內，科學的衡量標準是什麼？偏見成為一個，毒性成為另一個，對抗性攻擊等等。而如果你是一家金融服務公司，你可能會非常關心你有什麼樣的監管監督。所以你是否滿足了像模型風險管理這樣的要求。所以我想說，定義信任的方式有很多，這就是為什麼它變得非常關鍵。這不僅僅是關於採用 AI，而是你如何採用 AI，以及你是否真正足夠了解這項技術。

**Ena Freed:** 我想稍後再擴大範圍，但具體看看 Credo，我很好奇... 你不是一家小公司，但你知道，這是一個科技巨頭的世界，大部分的氧氣都被 OpenAI 和 Anthropic 這樣的公司，或者微軟和 Google 這樣的公司消耗掉了。當 Meta 提出那些巨大的收購要約，當微軟和 Google 可以將其與其他產品捆綁銷售時，作為 AI 領域的一家小公司，感覺如何？

**Navina Singh:** 我想... 作為 AI 領域的一家小公司，處理信任問題，將治理推向市場，非常困難。但你知道，如果這是一個容易解決的問題，我想我不會創業。話雖如此，也許可以稍微解釋一下，我認為挑戰來自於... 現在大家非常專注於投資 AI 創新，但我們沒有看到在安全和治理方面有相應的投資。

第二個挑戰是，我認為治理很多時候與監管聯繫在一起，我認為這很有問題，因為它不... 它完全是關於對齊、風險理解、測量、評估，而監管只是其中的一小部分。我認為第三件事是，我們實際上缺乏 AI 素養。每個人都想以速度和規模採用 AI。但你猜怎麼著？我們的勞動力還沒準備好。他們不明白要測量什麼，因為他們沒有那麼多地使用 AI。

**Ena Freed:** 我想談談更廣泛的對話，實際上我覺得我們現在比一年前談論得少了，那就是我們如何讓這些系統安全？我們如何減輕偏見？我們如何處理潛在的收入不平等？這困擾你嗎？對我來說，我一兩年前不認為我們在這些討論上進展得夠快。現在，感覺就像我們停止了談論它們，或者至少討論被推到了邊緣。我覺得巴黎 AI 峰會就是一個明顯的跡象。我們有布萊切利公園和首爾的會議，他們在那裡真正深入探討了一些非常棘手的問題。然後你到了巴黎，那就像一個貿易展。所有的公司都只是想在歐洲達成交易。我們需要進行那場對話嗎？我們如何重新啟動它？如何讓它回到中心舞台？

**Navina Singh:** 你知道，這是一個很好的問題。我想我們看到了兩面性。一面是，是的，公開場合可能沒有足夠的對話，但我們也看到了企業界的另一面，他們面臨著快速採用大量 AI 的巨大壓力。但你猜怎麼著？他們從過去學到了教訓，他們不能在不理解和沒有信任的情況下這樣做。所以即使可能沒有我們希望的那麼多公開討論，我們實際上看到了在試圖弄清楚...

**Ena Freed:** 因為企業本身想要它。

**Navina Singh:** 完全正確。因為企業希望確保他們是睜大眼睛前進的，而治理成為實現這種信任的關鍵。

**Ena Freed:** 你認為這能帶我們走多遠？因為感覺過去科技公司自我監管... 也許我會說必要但不足夠，這有點誇張。必要... 只是部分發生且不足夠。企業損害自己聲譽的風險，是否足以讓大多數公司做正確的事？

**Navina Singh:** 不，絕對不是。我認為這就是 AI 行動計畫是一個好的步驟，但它就像... 只是開始，對吧？所以當你說評估和標準框架時，你如何解讀它對企業意味著什麼？當你談論測量和確保開源生態系統安全時，那意味著什麼？所以有很多需要解讀的工作要做，不幸的是，我在那裡沒有看到太多行動，但需要做更多的工作。

**Ena Freed:** 有一件事被拿來作為信任和安全的對立面，我知道這不是你的立場，那就是「我們必須擊敗中國」，所以他們不會擔心這個，我們也不能擔心這個，我們必須全速前進。信任和安全... 是否必須以與中國競爭為代價？

**Navina Singh:** 絕對不是。我認為它們是相輔相成的，我們需要擊敗中國。我認為關鍵是，但我們也需要信任我們投入市場的系統。所以如果有一場關於最佳 AI 創新的對話，而我們沒有談論治理，我們沒有談論信任，我想我們... 我們就真的該把自己排除在外了。

**Ena Freed:** 鼓勵的跡象在哪裡？除了你的一些客戶顯然足夠認真地對待它，以至於購買你的服務之外，是什麼給了你樂觀的理由？

**Navina Singh:** 首先，我認為是我的團隊。我們有一個非常有使命感的團隊，他們非常關心這個話題，但我們只有 50 個人，所以需要更多。但我認為第二個是 AI 行動計畫。我認為那是一個非常好的步驟，它不是完整的步驟，但在思考整個 AI 供應鏈以及信任可能在哪裡崩潰方面，是一個非常好的步驟。我認為我們感到非常振奮，並且我們一直積極支持的是一個強大的評估和標準生態系統，真正思考開源和其中的風險等等。我認為第三件事是，我們需要更多的行動。我認為我們需要看到更多對像我們這樣的初創公司的投資。現在還不到 1%，甚至可能... 0.1%。所以我認為我們需要看到不僅在初創公司，而且在大型企業中，在治理、安全和風險評估方面有更多的投資。

**Ena Freed:** 我們是否有我們需要的標準來衡量信任和風險？在我看來，我再次... 我不懷疑你的許多客戶正在認真對待它，至少在他們不想損害自己聲譽的程度上，但今天是否有足夠的資訊來了解，或者當你部署 AI 時，它仍然是一個巨大的未知數？你是否可以提前相對安全地部署它，以一種值得信賴的方式，或者這只能在事後衡量？

**Navina Singh:** 我想我們現在正處於這個混亂的中間地帶。我想我們合作的大多數組織，他們知道對他們來說「好」是什麼樣子，但他們不知道那個「好」是否適用於更廣泛的生態系統。所以他們有自己的一套護欄和政策，就你的觀點而言，我們能否... 你知道，讓他們對此負責，那是一個棘手的問題。但第二件事是，我們看到了在 ISO、NIST 等標準生態系統中出現的早期跡象。但我認為需要做更多的工作。我們的步伐沒有跟上 AI 創新。我相信，要讓 AI 創新成功，要讓我們繼續在這場 AI 競賽中獲勝，並建立那個市場份額，我們絕對需要在信任的基礎上建設。

**Ena Freed:** 那是... 我們談了很多關於企業方面，公司出於自身利益所做的事情，但顯然公司的利益不一定與公眾的利益相同。我很好奇你對我們如何更多地討論「哪些數據不存在」有什麼看法？一個小故事。我當時在舊金山探索館看一個關於 AI 的精彩展覽，它非常細緻，真正深入探討了困難的問題。我喜歡的其中一件事是，他們有這些實體的檔案櫃，裡面有所有不同類型數據的資料夾，這些數據根本不存在於任何書面系統中。因此，它們不在大型語言模型中。我們知道這些系統有偏見。我們知道它們反映了在網際網路上占主導地位的聲音。我們如何填補這些空白？因為我的感覺是 AI 模型不會消失。唯一的機會就是讓它們變得更好。

**Navina Singh:** 是的，難題。又是難題。

**Ena Freed:** 完全正確。

**Navina Singh:** 我想我們看到三個層次的工作正在發生和沒有發生。所以一個是，顯然我們需要確保正在構建它的公司內部的系統需要有多方利益相關者的視角，我們談論多少 AI... 你知道，自動化和不需要人類，實際上是需要人類的。我們看到數據集缺失，沒有代表全球南方，舉個例子。所以你如何真正實現這一點？我認為第二件事是真正圍繞著什麼對業務重要，並透明地分享。我們一直在談論透明度... 那意味著什麼？對吧？所以我認為我們需要更清晰一點，不僅僅是從前沿模型提供商那裡，也包括應用程式開發者，關於他們用什麼數據集來構建這些系統，這是我們一直積極倡導的。

**Ena Freed:** 嗯，我們在華盛頓特區。感覺我... 如果我只問你難題，那是我失職。所以，你想看到什麼？你知道，本屆國會在 AI 上通過的法案很少。Cruz 參議員談到了幾項已經通過的法案，關於深度偽造和... 關於個人肖像權，這些都是非常狹窄的部分，但還沒有一個全面的法案。如果你可以有一個全面的 AI 監管，它會包含哪些部分？你會向在座的各位推薦什麼？

**Navina Singh:** 是的，我認為這是一個很好的問題。我們認為需要發生的三件事，我認為這是一個很好的起點。第一，我認為... 真正思考評估和需要進行哪些測量，因為它是如此依賴於具體的使用案例。你不能用一種「花生醬」的方法來測量 AI 中的所有東西，以確保它是安全的。所以，針對具體情境的測量，我認為絕對關鍵，這是我們正在積極努力的事情。

第二，我是披露報告的忠實信徒。它不必是公開的，但它必須存在於正在... 你知道... 銷售其 AI 模型的公司或正在構建應用程式的公司之間。我絕對相信披露報告，你如何構建這些系統，健全的系統卡，你使用了什麼樣的測試實踐，絕對關鍵，你可以把它... 覆蓋在一個透明度報告中。

然後我希望看到的最後一件事是... 對公司實際在信任和安全上投資多少，有更多的投入和理解。現在它是一個黑盒子。即使是我們合作的企業，我們也不知道他們實際上願意... 與 AI 創新相比，他們在 AI 信任和安全上花了多少錢。我很想看到這一點。

**Ena Freed:** 嗯，一如既往地非常感謝你，Navina。我們得在這裡結束了，但很感激。

**Navina Singh:** 非常感謝。

**Ena Freed:** 希望對話能繼續。

**Navina Singh:** 當然。

---
[**&laquo; 上一篇：心電感應的邊界：AlterEgo 的無聲語音介面**]({{ site.baseurl }}/sections/08-alterego-silent-speech.html) | [**下一篇：AI 工廠的基石：HPE 首席架構師談整合、規模與能源挑戰 &raquo;**]({{ site.baseurl }}/sections/10-hpe-infrastructure.html)