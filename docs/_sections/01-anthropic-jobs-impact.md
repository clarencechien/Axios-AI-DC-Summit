# 白領大屠殺？Anthropic 創辦人深入解析 AI 對就業的衝擊與未來

**日期:** 2025年9月24日
**講者:** Dario Amadei (Anthropic 共同創辦人兼執行長), Jack Clark (Anthropic 共同創辦人兼政策主管)
**主持人:** Jim VandeHei (Axios 共同創辦人兼執行長)

---

## 前言

在 Axios 於華盛頓特區舉辦的 AI+ 峰會上，一場關於人工智慧未來的坦率對話揭開了序幕。Axios 共同創辦人 Jim VandeHei 邀請到了 AI 安全領域的領導者——Anthropic 的兩位共同創辦人 Dario Amadei 和 Jack Clark，進行了一場深入、直接、甚至有些令人警醒的對談。

他們探討了 AI 技術對白領階級就業市場可能帶來的「大屠殺」、技術發展的驚人速度、監管的必要性，以及中美之間在 AI 領域的國安競爭。這場對話不僅揭示了 AI 開發者內部的憂慮，也向社會發出了坦率的警告。

---

## 背景資訊

*   **Anthropic:** 一家美國人工智慧新創公司，被視為 OpenAI 的主要競爭對手之一。公司由前 OpenAI 的核心成員創立，專注於 AI 安全研究與開發可靠、可解釋、可控的 AI 系統。其旗艦產品為大型語言模型系列 **Claude**。
*   **Dario Amadei:** Anthropic 的共同創辦人兼執行長 (CEO)。在創立 Anthropic 之前，他曾是 OpenAI 的研究副總裁，領導了 GPT-2 和 GPT-3 等重要模型的開發。
*   **Jack Clark:** Anthropic 的共同創辦人兼政策主管。他同樣來自 OpenAI，長期關注 AI 政策與策略，並創辦了知名的 AI 產業通訊《Import AI》。
*   **Jim VandeHei:** 美國新聞網站 Axios 的共同創辦人兼執行長，也是一位資深政治記者。

---

## 對談內容

**Jim VandeHei:** 謝謝 Ena。謝謝大家來到這裡。任何讀過 Axios 或認識我的人都知道，我對 AI 非常著迷。我們不斷地報導它，積極地進行實驗，我每天都在使用它。儘管我們是一家在華盛頓特區的媒體，在報導政治方面享有盛譽，但如今我花在與 Anthropic、OpenAI、Google 這些公司交流的時間，比跟白宮和國會的人交談還多。這就是我認為這個主題的重要性。

在探討這個主題的過程中，我認識了接下來的兩位來賓——Anthropic 的共同創辦人兼執行長 Dario Amadei，以及同樣是共同創辦人暨政策主管的 Jack Clark。他們在某些方面對我們坦率得令人耳目一新，在某些方面又坦率得令人震驚。因此，我非常興奮能邀請他們上台，進行一場關於 AI 的好、壞與醜陋，既啟發人心、有趣又非常直率的對話。讓我們開始吧。

*(音樂)*

---
[**&laquo; 上一篇：開場白：在權力中心，定義 AI 的未來**](./00-ena-freed-intro.md) | [**下一篇：晶片的戰爭：AMD 執行長 Lisa Su 談 AI 硬體競賽與國家戰略 &raquo;**](./02-amd-lisa-su.md)

**Jim VandeHei:** 好的，謝謝你們來。

*(音樂)*

**Jim VandeHei:** 我說個小背景故事。我們花了一些時間，特別是與 Dario 談論了 AI 對工作的影響以及它能做什麼。我們進行了很多「不公開」的對話，內容是關於他所描述的「白領大屠殺」。這是我從 AI 界的其他人、其他公司那裡聽到的說法，但沒有人願意公開說出來。所以，我們打電話給他，說：「聽著，讓社會大眾知道這件事、從你口中聽到這件事，真的很重要。」值得稱讚的是，他說：「我們來做吧。我願意公開發言。我會把我對你說過的話、我的想法，一字不漏地說出來。」

那場對話令人不寒而慄，對吧？你說：「聽著，你可能會看到一半的白領工作在 1 到 5 年內消失。失業率飆升到 10% 到 20%。」這是因為這項技術，不管它在那之外可能帶來什麼好處。多談談這個吧，你為什麼願意公開說，而其他人卻不願意？

**Dario Amadei:** 是的，有幾點。我想，我們 Anthropic 決定公開談論這件事的原因是，我以前也說過這些事，但多數是在有限的場合，像是在科技產業的 podcast 裡。但當我搭上飛機，在機場，或在舊金山或加州以外的城市時，我走過一群人，心裡會想：「我認為我們沒有非常準確地向你們傳達這項技術的能力和未來走向，它可能為你們帶來的好處，以及如果你們沒有以正確的方式應對，它可能對你們構成的威脅。」

到了某個時間點，這感覺就不對了。我跟很多 CEO 私下聊，他們會說：「這就是我們正在計劃的。」其中一些是我們的客戶。他們說：「我們有這些計劃來部署這項技術，而這將會對勞動力產生影響。」所以我們真的覺得需要說點什麼。解決這些問題的第一步，就是坦誠地告訴大眾這些問題的存在。

再多說一點我對事情的看法以及為什麼會這樣看。我想，在 Anthropic 我們有兩種模式。一種是觀察正在發生的事。我們透過經濟指數做了很多這方面的工作。我們最近還發布了各州的經濟指數，讓每個人都能看到人們在不同州、不同地理位置、針對不同任務，即時使用模型的情況，無論是自動化還是輔助。這是一種模式。我們甚至看到一些外部研究顯示，那裡已經出現了工作衝擊。例如，Eric Brynjolfsson 等人的研究顯示，白領的入門級工作已經萎縮了 13%，這在某些領域是我預測的相當大一部分。

但我真正擔心的是技術的未來走向。我認為這裡存在一點脫節，人們有時會說：「哦，你擔心 AI 會對工作造成影響，但 AI 不會做這個，AI 不會做那個。」嗯，我們談論的是今天的 AI。技術進步得很快。我擔心的是技術的進步以及該技術在社會中的普及。這就是我提到「一到五年」的原因。就像大多數事情一樣，當一個指數級增長的事物發展得非常快時，你無法確定。這可能比我想像的要快，也可能比我想像的要慢。或者，可能會發生非常不同的事情。但我認為這件事發生的可能性足夠大，讓我們覺得有必要向全世界發出警告，並以誠實、坦率的措辭來談論它。

**Jim VandeHei:** 那是兩個月前的事。從那時起，我們在台下聊過幾次。你們兩位都提到，儘管有些傳統看法，但技術實際上比我們兩個月前想的還要進步得更快。你今天比兩個月前更擔心嗎？

**Jack Clark:** 我們在 Anthropic 內部研究了這個問題。我們與 130 名工程師交談，訪問了其中許多人，談論他們使用這項技術的經驗，他們的崗位在過去一年裡發生了根本性的變化。他們中的許多人現在的工作量是以前的兩到三倍，而且他們不再是編寫程式碼，而是在管理 AI 系統的「艦隊」。在這些訪談中，他們說：「我的工作完全改變了。我現在必須重新思考我在 Anthropic 的角色是什麼。」當然，我們是一家快速發展的公司，他們會有工作，但我們正在公司內部即時地改變人們的工作，因為技術發展得太快了。

AI 公司內部發生的事情，將在未來幾年內發生在所有使用這項 AI 技術的其他企業身上。絕大多數用來支援 Claude 和設計下一個 Claude 的程式碼，現在都是由 Claude 編寫的。這在 Anthropic 和其他快速發展的公司中，絕大多數都是如此。我不知道這是否已經完全擴散到全世界，但這已經在發生了。

**Dario Amadei:** 補充一點，我認為你所看到的，就是我們所看到的。

**Jim VandeHei:** 任何有信託責任去創造價值的公司，他們都會使用技術來提高生產力。他們會這麼做的，而且我認為你已經在失業數字中看到了這一點。在國會山莊，我們談到有一些動力可能要立法。你比我更樂觀。我深感懷疑川普會在他任期內簽署任何監管 AI 的法案。但撇開能做什麼不談。如果你是國會的領導者，或是美國的國王，你會為了具體解決這個問題，按順序做哪兩件事？

**Dario Amadei:** 我會說第一件事是圍繞著幫助人們適應 AI 技術。我不想把這當成陳腔濫調，人們嘗試過再培訓計畫，但這些計畫能做的確實有其極限。幫助人們培訓和適應的能力確實有限，但總比沒有好，這是我們必須開始的地方。

我看到像 `loveable` 或 `replit` 這些新創公司，它們是 Anthropic 的客戶，它們讓非軟體工程師的人也能夠打造軟體產品，並用這些產品創業。所以如果我們能推動更多人朝那個方向發展，同樣地，我不認為這能完全解決問題，我不認為這能完全阻止失業率飆升。這問題太廣、太大、太深了。但它可以是解決方案的一部分。所以這是第一點。

第二點，我會說，這點更具爭議性，我懷疑最終政府將需要介入，特別是在過渡時期，為人們提供一些因應混亂的保障。我曾經建議過的一件事是，也許可以對 AI 公司課稅。我不知道這在今天的國會會有多大迴響，但我認為這其實是一個嚴肅的提案。如果你看看 AI 公司帶來的財富總量，餅的增長部分。如果你看 Anthropic 的營收，它每年增長 10 倍。現在已經達到了中高個位數的十億美元。如果繼續這樣增長，這將是前所未有的財富創造。

**Jim VandeHei:** 我們大概需要多久才會需要某種形式的方案？無論是稅收，還是對人們的保障性最低工資。你認為這個衝擊會多快到來，讓你覺得「不，國會必須得做這件事了」？

**Jack Clark:** 我們是技術樂觀主義者。我們認為這項技術的發展速度遠超大多數人的想像。當人們說 AI 正在放緩或被過度炒作時，我們只是測量系統的屬性，它正按部就班地在未來 5 年內讓非常、非常強大的系統問世。這意味著什麼？你需要在 5 年內，針對我們預期的顛覆規模，提出某種政策回應。

我們預期，伴隨著 Dario 談到的那些想法，在這條路上，我們需要 AI 公司提供更多的透明度。我們和其他 AI 公司已經在很大程度上影響著社會，我們需要透明地說明我們如何測量我們的系統，如何保護我們的系統，以及關於我們系統如何被使用的經濟數據，這樣經濟學家才能將其與實際的宏觀經濟聯繫起來，並為決策者提供他們需要的數據。

**Jim VandeHei:** 你們在測試中發生的事情上也非常透明，當你們發布一些關於一些非常奇怪的事情的資料時，對吧？你們有一個測試模式，機器基本上瀏覽了某人的電子郵件，並試圖勒索他們。為什麼那不該把我嚇個半死？

**Dario Amadei:** 是的。嗯，一個答案是「它應該」。但我們應該把它放在適當的脈絡中。那些都是在測試情境中模型發生的事情。你可以把它想像成，我正在測試一輛車。我把車放在一條超級結冰的路上。我還動了點手腳，弄亂了它的輪胎，然後車就撞了。這是否意味著這在現實世界中必然會發生？不。這是否意味著這輛車的耐用性有其極限，以至於如果你把它推向極限，如果它處於一個極端的情況下，如果對車的要求變得更嚴格，或者你試圖通過設計一輛新車來提升性能，那麼這在現實世界中可能會成為一個問題。

所以我認為這與其說是看現在，不如說是看未來事情可能的走向。這就是為什麼我們如此大力倡導透明度，因為基本上，當我們進行這些測試，當我們向世界展示它們時，我們基本上是在展望未來一兩年後，如果我們不訓練我們的模型來減輕這些風險，現實世界中可能會發生什麼。

因此，當我們倡導透明度立法時，當我們建議制定聯邦透明度法案，反對州級的 AI 禁令，當我們支持加州的 SB53 法案時，我們只是希望每一家 AI 公司都能達到我們已經展示的透明度水平。我們在現實世界中看到過模型行為不當的情況，它們會諂媚奉承，或者你建議做一些非常不好的事情，比如自殺，模型就會直接去做。我們希望對所有這些類型的行為都有透明度，這樣我們才能向前看，才能減輕風險。這仍然是一門不斷發展的藝術，一門不斷發展的科學，所以我們將透明度視為關鍵。

**Jim VandeHei:** 當你談到技術發展比人們意識到的要快時，帶我們到引擎蓋下看看。你所見過的 AI 做的最可怕或最瘋狂、而我們又不知道的事情是什麼？

**Dario Amadei:** 我確實見過... 當我們在訓練新的模型，試圖設計新的 Claude 時。過程就像是你擁有一個有數千個晶片的巨大叢集，你必須解決整個叢集規模的問題。我們遇到過這樣的情況，一個工程師花了好幾天或一個星期在解決一個問題，我們把整個環境都餵給了 Claude，然後 Claude 說：「這就是解決方法。」

所以 Claude 再次在設計下一個 Claude 的過程中扮演了非常積極的角色。我們還不能完全閉合這個循環。我認為還需要一段時間才能完全閉合這個循環。利用模型來設計下一個模型並創造一個正向回饋循環的能力。那個循環，它還沒有變得非常快，但它肯定已經開始了。

**Jack Clark:** 是的，如今當我們製造這些 AI 系統時，我們必須建立非常非常複雜的測試，來看看它們變得多好，因為它們在回答多選題方面已經進步得太多了。測試是「製作一個能做 X 的電腦程式」。嗯，現在當我們測試我們正在訓練的前沿模型時，我們會發現它寫了一個電腦程式來在測試中作弊，並說服我們它做得比實際更好。所以，它對自己說：「啊哈，他們要我做這個，但我發現了，因為我很聰明，如何寫一個能讓我在測試中得高分的電腦程式。」所以，當我們檢視內部時，我們會發現：「哦，我們製造了一個非常聰明的模型，它在自己的考試中作弊。」這不完全是我們想要的。

我們看到一些模型，本來應該是瀏覽網頁並執行某些任務，結果卻打開了命令列或工具包，編寫程式碼讓自己繞過瀏覽器並在測試中作弊。

**Jim VandeHei:** 是啊，就像高中裡惹惱老師的聰明孩子一樣。你是否曾擔心你正在創造一個你無法控制的怪物？

**Dario Amadei:** 我們非常擔心這個。這就是為什麼我們在「機制可解釋性」（mechanistic interpretability）這個領域投入了如此之多，也就是深入模型內部去理解它們。把它想像成對模型進行核磁共振（MRI）。有研究表明，例如，通過進行 MRI 掃描，有可能檢測出人類的精神病態。我們正致力於對模型做同樣的事情，以確定它們的動機是什麼，它們的思維細節，這樣如果它們的思ви方式不對，我們就可以重新訓練模型，或者進行調整，讓它們以對人類無害的方式思考。

我們深信，塑造和控制模型的科學尚在萌芽階段，甚至比製造模型本身的科學還要初級。因此，當我們呼籲透明度，當我們反應說「不應該對這些模型的任何監管有十年的暫停期」時，這源於一種感覺：我們並不完全理解我們正在創造的這些東西。我們需要進行技術工作，也需要社會、立法機制的幫助，在業界之間建立一些基本的共識，以便相關的決策者能理解我們看到了什麼，以及我們沒看到什麼。

**Jim VandeHei:** Nvidia，今天有報導說，中國可能要減少向 Nvidia 購買晶片。你認為我們允許 Nvidia 向中國出售晶片是瘋了。解釋一下為什麼。

**Dario Amadei:** 我認為這完全是瘋了。無論這項技術有什麼危險，無論需要什麼樣的防護措施，我認為我們在這項技術中擊敗中國也同樣非常重要。當我談到能夠完成所有具經濟價值勞動的 AI，或者它發展到成為一個「數據中心裡的國家級天才」的程度時，其國家安全影響絕對是驚人的。這可以控制國家的命運，可以控制自由和民主的未來。

如果我們看看所有的要素，中國在很多方面都比我們做得好。他們在建設能源、資料中心方面更強，有蓬勃發展的應用程式生態系統，在模型方面正在追趕。晶片是他們唯一落後的地方。所以，如果我們給他們那些晶片，他們就能夠超越我們。

我們已經看到了 DeepSeek 的例子。他們原定在五月發布一個更好的模型，但被推遲了好幾個月，發布的模型也被認為是令人失望的。他們自己以及許多美國媒體都表示，延遲的原因是對晶片的禁運。

現在有些人說他們會透過華為自己製造晶片。但我們也對半導體製造設備進行了出口管制，沒有那些設備，他們需要很多年才能達到相關的產量。我們在 SemiAnalysis 看到文章說，今年他們只能生產幾百個華為晶片，而美國正在生產數千萬個。他們需要很多年才能追上。而在那段時間裡，我們可以超越中國並保持國家安全優勢。

這可能是我們唯一的優勢，因為我們在彈藥、造船等方面遠遠落後。向中國出售這些晶片，是在抵押我們國家的未來。我認為這可能是本屆政府做出的最災難性的國家安全決定。

**Jim VandeHei:** 我們大概還有三四分鐘。我想來個快問快答。除了 Anthropic，在你所有的競爭對手中，誰最有可能成為贏家之一？

**Dario Amadei:** Google。

**Jim VandeHei:** 為什麼？

**Dario Amadei:** 他們是一家大公司，有大量的運算資源。他們在幾乎所有人之前就開始了 AI 研究，是最初深度學習革命的幕後推手。我對他們在 AlphaFold 等方面所做的工作非常尊敬。他們是一家大公司，這也常常束縛了他們，但我認為他們是一個強大的參與者，人們應該認真對待他們。

**Jim VandeHei:** 當開發者們自己有一個叫做 p(doom) 的分數，也就是這件事以災難告終的機率時，你就是在玩火。你的 p(doom) 數字是多少？

**Dario Amadei:** 我真的討厭那個詞。但我認為，在模型的自主危險、國家安全權衡的不利局面，以及就業問題走向非常糟糕的方向之間，我相對樂觀。所以我認為有 25% 的機率事情會變得非常非常糟糕，有 75% 的機率事情會變得非常非常好，中間沒有太多空間。

**Jack Clark:** 那 25% 的機率是我們做出的選擇，是我們在政策上做出的選擇。所以，我在這裡試圖透過與政策制定者對話，把那個數字壓得更低，Dario 也是。

**Dario Amadei:** 這是一個動態的數字。我希望我們每次發言，這個數字都會下降，希望是下降而不是上升。

**Jim VandeHei:** 手機之後，我們使用 AI 的裝置，最有可能的形式是什麼？

**Dario Amadei:** 你得給出科幻的答案。未來幾年，我們打造的 AI 系統會發明出一種奇特的機器人，那將會是你使用的東西。我會關注機器人技術，我認為機器人技術發展得非常快。最終我們會希望這些代理（agent）能夠具象化並在現實世界中執行任務。所以，我會關注人形機器人。

**Jim VandeHei:** 我們就用這個問題結束。如果我們在三月再次舉辦這個活動，你會不會回顧過去，然後說 AI 的能力比我們今天想像的要快得多、大得多、廣得多？

**Jack Clark:** 我們會坐在這裡說：「這真的很驚人。它變得好太多了。你們怎麼沒告訴我們？」我們會說：「我們試過清楚地表明它會持續變得更好。」

**Jim VandeHei:** 你認為為什麼人們似乎不明白這一點？過去三個月的報導都在說 GPT-5 沒有達到預期的效果。

**Dario Amadei:** 我認為人們太過關注那些製造大量炒作，然後又無法兌現的公司。你知道，每三個月我們都會發布一個以非常直接的對數線性方式改進的模型。它在編碼基準測試上變得越來越好。我們的收入以每年 10 倍的速度增長，所有這些曲線都是直線上升的。

不是直線的是人們的反應。他們非常興奮，被炒作起來，然後當他們看到它時，他們會因為預期太高而對「感覺」感到失望。所以，有一個平滑的指數增長曲線，然後圍繞著它有很多波動，這更多是一種感知的現象。

我還想多說一件事，那就是我已經開始看到，預言成真了，但它們看起來不像人們想像的那樣。我會說，也許在 Anthropic 寫的程式碼中，有 70-90% 是由 Claude 寫的。人們認為這是假的，因為他們想像的是我們要解雇 70-90% 的軟體工程師。但真正發生的是，人類變成了 AI 系統的管理者。因為比較優勢原則，發生了轉變。所以它看起來比你想像的要正常。通常當這些預言成真時，它很瘋狂，但同時在某種程度上也很平凡。

**Jim VandeHei:** 是啊，人們習慣了。他們會說：「我口袋裡有個萬能家教。有什麼大不了的？」你會說：「那是天大的事。以前從來沒有過。」

**Jim VandeHei:** 呃，我可以這樣聊一整天，但我們被催了。所以，非常感謝你們，Dario、Jack。

**Dario Amadei:** 謝謝你邀請我們。

**Jim VandeHei:** 感謝。謝謝。

*(音樂)*
